{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12672352,"sourceType":"datasetVersion","datasetId":8008289},{"sourceId":12672592,"sourceType":"datasetVersion","datasetId":8008453},{"sourceId":12682250,"sourceType":"datasetVersion","datasetId":8014637},{"sourceId":12691555,"sourceType":"datasetVersion","datasetId":8020566},{"sourceId":12745805,"sourceType":"datasetVersion","datasetId":8057247},{"sourceId":12745945,"sourceType":"datasetVersion","datasetId":8057351},{"sourceId":12756131,"sourceType":"datasetVersion","datasetId":8064027},{"sourceId":12767685,"sourceType":"datasetVersion","datasetId":8071338},{"sourceId":12829684,"sourceType":"datasetVersion","datasetId":8113799}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Converting xlsx file into csv file**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Step 1: Read the Excel file\nxlsx_file = '/kaggle/input/why-mrmr-svm-rocks/common gene.xlsx'  # Replace with your actual file name\ndf = pd.read_excel(xlsx_file)\n\n# Step 2: Transpose the data\ndf_transposed = df.T\n\n# Step 3: Save the transposed data as a CSV file\ncsv_file = 'common gene.csv'  # Desired output file name\ndf_transposed.to_csv(csv_file, index=True)\n\nprint(f\"Transposed file saved as '{csv_file}'\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-04T18:03:20.595567Z","iopub.execute_input":"2025-08-04T18:03:20.595941Z","iopub.status.idle":"2025-08-04T18:03:20.642860Z","shell.execute_reply.started":"2025-08-04T18:03:20.595916Z","shell.execute_reply":"2025-08-04T18:03:20.641780Z"}},"outputs":[{"name":"stdout","text":"Transposed file saved as 'common gene.csv'\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# feature selection using MiG","metadata":{}},{"cell_type":"markdown","source":"**for GSE18520**","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\nfrom sklearn.feature_selection import SelectKBest, mutual_info_classif\n\n# Load your dataset (make sure the last column is 'Class')\ndata = pd.read_csv('/kaggle/input/why-mrmr-svm-rocks/transposed_merged_GSE18520_new.csv')  # Replace with your actual path\n\n# Separate features and target\nX = data.drop(columns=['Class'])\ny = data['Class']\n\n# Select top 3620 features using Mutual Information Gain\nselector = SelectKBest(score_func=mutual_info_classif, k=3620)\nX_selected = selector.fit_transform(X, y)\n\n# Get the names of the selected features\nselected_features = X.columns[selector.get_support()]\n\n# Combine selected features and class column\nselected_data = pd.DataFrame(X_selected, columns=selected_features)\nselected_data['Class'] = y.values\n\n# Save the result to a new CSV\nselected_data.to_csv('MiG_selected_3620_features.csv', index=False)\n\n\n\nprint(\"Selected top 3620 features using MiG and saved to 'MiG_selected_3620_features18520.csv'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:37:17.218869Z","iopub.execute_input":"2025-08-06T10:37:17.219178Z","iopub.status.idle":"2025-08-06T10:37:30.763369Z","shell.execute_reply.started":"2025-08-06T10:37:17.219152Z","shell.execute_reply":"2025-08-06T10:37:30.762599Z"}},"outputs":[{"name":"stdout","text":"Selected top 3620 features using MiG and saved to 'MiG_selected_3620_features18520.csv'\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**for GSE26712**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_selection import SelectKBest, mutual_info_classif\n\n# Load your dataset (make sure the last column is 'Class')\ndata = pd.read_csv('/kaggle/input/why-mrmr-svm-rocks/transposed_merged_GSE26712_new.csv')  # Replace with your actual path\n\n# Separate features and target\nX = data.drop(columns=['Class'])\ny = data['Class']\n\n# Select top 3620 features using Mutual Information Gain\nselector = SelectKBest(score_func=mutual_info_classif, k=1290)\nX_selected = selector.fit_transform(X, y)\n\n# Get the names of the selected features\nselected_features = X.columns[selector.get_support()]\n\n# Combine selected features and class column\nselected_data = pd.DataFrame(X_selected, columns=selected_features)\nselected_data['Class'] = y.values\n\n# Save the result to a new CSV\nselected_data.to_csv('MiG_selected_1290_features.csv', index=False)\n\nprint(\"Selected top 1290 features using MiG and saved to 'MiG_selected_1610_features26712.csv'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:37:36.746889Z","iopub.execute_input":"2025-08-06T10:37:36.747422Z","iopub.status.idle":"2025-08-06T10:37:40.754351Z","shell.execute_reply.started":"2025-08-06T10:37:36.747400Z","shell.execute_reply":"2025-08-06T10:37:40.753685Z"}},"outputs":[{"name":"stdout","text":"Selected top 1290 features using MiG and saved to 'MiG_selected_1610_features26712.csv'\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# LASSO Selection","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/why-mrmr-svm-rocks/transposed_merged_GSE26712_new.csv')  # üîÅ Replace with your file path\n\n# Separate features and target\nX = data.iloc[:, :-1]\ny = data.iloc[:, -1]\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split dataset (optional)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# Apply LASSO with cross-validation\nlasso = LassoCV(cv=10, random_state=90).fit(X_train, y_train)\n\n# Get absolute coefficients\ncoef = np.abs(lasso.coef_)\n\n# Get indices of top 3620 features\ntop_k = 1290\ntop_indices = np.argsort(coef)[-top_k:]\n\n# Get feature names\nselected_features = X.columns[top_indices]\n\n# Filter original data to keep selected features\nX_selected = X[selected_features]\n\n# Add class label back\nX_selected['Class'] = y.values\n\n# Save to CSV\nX_selected.to_csv('lasso_top1290_selected_features_GSE26712.csv', index=False)\n\nprint(f\"‚úÖ Top {top_k} LASSO-selected features saved to 'lasso_top1290_selected_features_GSE26712.csv'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:32:47.433764Z","iopub.execute_input":"2025-08-06T14:32:47.434096Z","iopub.status.idle":"2025-08-06T14:32:55.973705Z","shell.execute_reply.started":"2025-08-06T14:32:47.434070Z","shell.execute_reply":"2025-08-06T14:32:55.972869Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.302e-03, tolerance: 8.481e-04\n  model = cd_fast.enet_coordinate_descent(\n/tmp/ipykernel_36/1060177646.py:38: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_selected['Class'] = y.values\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Top 1290 LASSO-selected features saved to 'lasso_top1290_selected_features_GSE26712.csv'\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\n# Load the original CSV file\ninput_file = '/kaggle/working/anova_top3620_selected_features_GSE18520.csv'  # üîÅ Replace with your actual file name\ndf = pd.read_csv(input_file)\n\n# Transpose the DataFrame\ndf_transposed = df.T\n\n\n# Save the transposed DataFrame\noutput_file = 'transposed_output_anova_18520.csv'  # üìù Output file name\ndf_transposed.to_csv(output_file, index=True)\n\nprint(f\"new Transposed file saved as '{output_file}'\")\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:48:47.477094Z","iopub.execute_input":"2025-08-06T14:48:47.477443Z","iopub.status.idle":"2025-08-06T14:48:47.850298Z","shell.execute_reply.started":"2025-08-06T14:48:47.477418Z","shell.execute_reply":"2025-08-06T14:48:47.849537Z"}},"outputs":[{"name":"stdout","text":"new Transposed file saved as 'transposed_output_anova_18520.csv'\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# ANOVA selection","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/why-mrmr-svm-rocks/transposed_merged_GSE26712_new.csv')  # üîÅ Replace with your CSV file path\n\n# Separate features and target\nX = data.iloc[:, :-1]  # All columns except the last (features)\ny = data.iloc[:, -1]   # Last column (class label)\n\n# Split the data (optional for model testing)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Apply ANOVA F-test to select top 3620 features\nk = 1290\nselector = SelectKBest(score_func=f_classif, k=k)\nselector.fit(X_train, y_train)\n\n# Get selected feature names\nselected_features = X.columns[selector.get_support()]\n\n# Filter original dataset to keep only selected features + class column\nX_selected = X[selected_features]\nX_selected['Class'] = y.values\n\n# Save the selected features to a CSV file\nX_selected.to_csv('anova_top1290_selected_features_GSE26712.csv', index=False)\n\nprint(f\"‚úÖ Top {k} ANOVA-selected features saved to 'anova_top_selected_features.csv'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:47:27.122170Z","iopub.execute_input":"2025-08-06T14:47:27.122537Z","iopub.status.idle":"2025-08-06T14:47:27.625343Z","shell.execute_reply.started":"2025-08-06T14:47:27.122510Z","shell.execute_reply":"2025-08-06T14:47:27.624571Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1764302099.py:25: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_selected['Class'] = y.values\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Top 1290 ANOVA-selected features saved to 'anova_top_selected_features.csv'\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# **extracting common genes from both datasets.**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# --- Load common genes (single row, 421 gene names) ---\ncommon_genes = pd.read_csv('/kaggle/input/newcommongene/common gene.csv', header=None).iloc[0].tolist()\ncommon_genes = sorted(common_genes)  # Sort common genes alphabetically\n\n\n# --- Process GSE18520 ---\nprint(\"Processing GSE18520...\")\nall_genes_df18520 = pd.read_csv('/kaggle/input/mig-classigication/MiG_selected_3620_features_GSE18520.csv')\n\n# Identify if 'Class' or 'Sample' column exists\nnon_gene_cols = [col for col in ['Sample', 'Class'] if col in all_genes_df18520.columns]\n\n# Get gene columns, sort alphabetically\ngene_cols = sorted([col for col in all_genes_df18520.columns if col not in non_gene_cols])\nall_genes_df18520 = all_genes_df18520[non_gene_cols + gene_cols]\n\n# Filter to keep only common genes\nfiltered_gene_cols = [gene for gene in gene_cols if gene in common_genes]\nfiltered_df18520 = all_genes_df18520[non_gene_cols + filtered_gene_cols]\n\n# Reorder filtered genes alphabetically (again, for consistency)\nfiltered_df18520 = filtered_df18520[non_gene_cols + sorted(filtered_gene_cols)]\n\n# Save\nfiltered_df18520.to_csv('filtered_common_genes18520.csv', index=False)\nprint(\"Saved 'filtered_common_genes18520.csv'\")\n\n\n# --- Process GSE26712 ---\nprint(\"Processing GSE26712...\")\nall_genes_df26712 = pd.read_csv('/kaggle/input/mig-classigication/MiG_selected_1290_features_GSE26712.csv')\n\n# Identify if 'Class' or 'Sample' column exists\nnon_gene_cols = [col for col in ['Sample', 'Class'] if col in all_genes_df26712.columns]\n\n# Get gene columns, sort alphabetically\ngene_cols = sorted([col for col in all_genes_df26712.columns if col not in non_gene_cols])\nall_genes_df26712 = all_genes_df26712[non_gene_cols + gene_cols]\n\n# Filter to keep only common genes\nfiltered_gene_cols = [gene for gene in gene_cols if gene in common_genes]\nfiltered_df26712 = all_genes_df26712[non_gene_cols + filtered_gene_cols]\n\n# Reorder filtered genes alphabetically\nfiltered_df26712 = filtered_df26712[non_gene_cols + sorted(filtered_gene_cols)]\n\n# Save\nfiltered_df26712.to_csv('filtered_common_genes26712.csv', index=False)\nprint(\"Saved 'filtered_common_genes26712.csv'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T20:04:03.678387Z","iopub.execute_input":"2025-08-08T20:04:03.678636Z","iopub.status.idle":"2025-08-08T20:04:06.585327Z","shell.execute_reply.started":"2025-08-08T20:04:03.678614Z","shell.execute_reply":"2025-08-08T20:04:06.584299Z"}},"outputs":[{"name":"stdout","text":"Processing GSE18520...\nSaved 'filtered_common_genes18520.csv'\nProcessing GSE26712...\nSaved 'filtered_common_genes26712.csv'\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# File paths\nfile1 = \"/kaggle/working/combined_top421_common_genes_mrmrsvmrfe.csv\"  # üîÅ Replace with your CSV path\nfile2 = \"/kaggle/input/anova-lasso-mig/Total common genes filtered from both dataset for feature extraction accuracy.csv\"  # üîÅ Replace with your CSV path\nfile3 = \"/kaggle/input/newcommongene/common gene.csv\"\n# Read only the first row from each file\nrow1 = pd.read_csv(file1, nrows=1)\nrow2 = pd.read_csv(file2, nrows=1)\nrow3 = pd.read_csv(file3, nrows=1)\n# Convert to list for comparison\nrow1_list = row1.values.tolist()[0]\nrow2_list = row2.values.tolist()[0]\nrow3_list = row3.values.tolist()[0]\n\n# Compare\nif row3_list == row2_list:\n    print(\"‚úÖ First rows are the SAME.\")\nelse:\n    print(\"‚ùå First rows are DIFFERENT.\")\n    print(\"\\nFirst row of File 1: \", row3.shape)\n    print(\"First row of File 2: \", row2.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T16:27:35.153216Z","iopub.execute_input":"2025-08-13T16:27:35.153572Z","iopub.status.idle":"2025-08-13T16:27:35.243431Z","shell.execute_reply.started":"2025-08-13T16:27:35.153548Z","shell.execute_reply":"2025-08-13T16:27:35.242085Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1863968173.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mrow1_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mrow2_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mrow3_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Compare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}],"execution_count":20},{"cell_type":"code","source":"import pandas as pd\n\n# File paths\nfile1 = \"/kaggle/working/combined_top421_common_genes_mrmrsvmrfe.csv\"\nfile2 = \"/kaggle/input/anova-lasso-mig/Total common genes filtered from both dataset for feature extraction accuracy.csv\"\nfile3 = \"/kaggle/input/newcommongene/common gene.csv\"\n\n# Read only the headers (no data)\ncols1 = pd.read_csv(file1, nrows=0).columns.tolist()\ncols2 = pd.read_csv(file2, nrows=0).columns.tolist()\ncols3 = pd.read_csv(file3, nrows=0).columns.tolist()\n\n# Compare\nif cols1 == cols2:\n    print(\"‚úÖ Columns are the SAME.\")\nelse:\n    print(\"‚ùå Columns are DIFFERENT.\")\n    print(\"\\nColumns in File 2 but not in File 3:\", set(cols2) - set(cols3))\n    print(\"Columns in File 3 but not in File 2:\", set(cols3) - set(cols2))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T16:36:50.367387Z","iopub.execute_input":"2025-08-13T16:36:50.367764Z","iopub.status.idle":"2025-08-13T16:36:50.631624Z","shell.execute_reply.started":"2025-08-13T16:36:50.367740Z","shell.execute_reply":"2025-08-13T16:36:50.630724Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Columns are the SAME.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import pandas as pd\n\n# File paths\nfile1 = \"/kaggle/working/combined_top421_common_genes_mrmrsvmrfe.csv\"\nfile2 = \"/kaggle/input/anova-lasso-mig/Total common genes filtered from both dataset for feature extraction accuracy.csv\"\n#file3 = \"/kaggle/input/newcommongene/common gene.csv\"\n\n# Load files\ndf1 = pd.read_csv(file1)\ndf2 = pd.read_csv(file2)\ndf3 = pd.read_csv(file3)\n\n# --- Step 1: Compare number of rows ---\nprint(f\"File 1 rows: {df1.shape[0]}\")\nprint(f\"File 2 rows: {df2.shape[0]}\")\nprint(f\"File 3 rows: {df3.shape[0]}\")\n\nif df1.shape[0] == df2.shape[0]:\n    print(\"‚úÖ All files have the SAME number of rows.\")\nelse:\n    print(\"‚ùå Files have different number of rows.\")\n\n# --- Step 2: Find missing rows ---\ndef find_missing(df_a, df_b, name_a, name_b):\n    missing = pd.concat([df_a, df_b]).drop_duplicates(keep=False)\n    if not missing.empty:\n        print(f\"\\nRows present in {name_a} but not in {name_b}:\")\n        print(missing)\n    else:\n        print(f\"\\nNo missing rows between {name_a} and {name_b}.\")\n\nfind_missing(df1, df2, \"File 1\", \"File 2\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T16:40:59.546943Z","iopub.execute_input":"2025-08-13T16:40:59.547640Z","iopub.status.idle":"2025-08-13T16:40:59.708120Z","shell.execute_reply.started":"2025-08-13T16:40:59.547613Z","shell.execute_reply":"2025-08-13T16:40:59.706918Z"}},"outputs":[{"name":"stdout","text":"File 1 rows: 258\nFile 2 rows: 253\nFile 3 rows: 0\n‚ùå Files have different number of rows.\n\nRows present in File 1 but not in File 2:\n      ABCA8    ABHD11     ACAA2      ACTB   ADAMTS3     ADH1C    AGPAT1  \\\n0  0.956914  0.681094  0.952189  0.855519  0.526745  0.491551  0.852819   \n1  0.961762  0.709205  0.959425  0.866688  0.331835  0.322190  0.840304   \n2  0.961838  0.628602  0.943197  0.909876  0.423280  0.485303  0.877551   \n3  0.903229  0.791392  0.933869  0.846821  0.494668  0.385425  0.850491   \n4  0.957672  0.658076  0.933604  0.883859  0.666118  0.729337  0.879824   \n\n     AGPAT2      AGRN    AKAP13  ...     WNT2B     WNT5A     YIPF2   ZFP36L1  \\\n0  0.746679  0.865668  0.775650  ...  0.888411  0.928213  0.756436  0.225296   \n1  0.758924  0.712698  0.845397  ...  0.896842  0.840832  0.759424  0.187101   \n2  0.752400  0.750965  0.745091  ...  0.854621  0.923891  0.734418  0.207488   \n3  0.776174  0.808495  0.820668  ...  0.731024  0.879690  0.794660  0.225974   \n4  0.797317  0.828131  0.668048  ...  0.877714  0.912208  0.776869  0.249812   \n\n      ZFPM2     ZMYM2    ZNF277    ZNF302   ZNF37BP  Class  \n0  0.953696  0.869479  0.733177  0.660358  0.423356      0  \n1  0.812906  0.874232  0.694458  0.570197  0.400940      0  \n2  0.916057  0.818857  0.681649  0.604374  0.306925      0  \n3  0.901615  0.862398  0.575703  0.569656  0.439501      0  \n4  0.933304  0.861547  0.606357  0.723831  0.475707      0  \n\n[5 rows x 422 columns]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import pandas as pd\n\n# File paths\nfile1_path = \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv\"\nfile2_path = \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv\"\nfile3_path = \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv\"\nfile4_path = \"/kaggle/input/anova-lasso-mig/Total common genes filtered from both dataset for feature extraction accuracy.csv\"\nfile5_path = \"/kaggle/working/combined_top421_common_genes_mrmrsvmrfe.csv\"\n\n# Load CSV files\ndf1 = pd.read_csv(file1_path)\ndf2 = pd.read_csv(file2_path)\ndf3 = pd.read_csv(file3_path)\ndf4 = pd.read_csv(file4_path)\ndf5 = pd.read_csv(file5_path)\n\n# Print shapes\nprint(df1.shape)\nprint(df2.shape)\nprint(df3.shape)\nprint(df4.shape)\nprint(df5.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T16:24:16.980041Z","iopub.execute_input":"2025-08-13T16:24:16.980360Z","iopub.status.idle":"2025-08-13T16:24:17.130915Z","shell.execute_reply.started":"2025-08-13T16:24:16.980319Z","shell.execute_reply":"2025-08-13T16:24:17.130159Z"}},"outputs":[{"name":"stdout","text":"(258, 422)\n(258, 422)\n(258, 422)\n(253, 422)\n(258, 422)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# **ml model accuracy apply part**\nin this section, we have to try on different feature selection model for proving that the model we have selected is better than them in this case.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_selection import mutual_info_classif, SelectKBest\nfrom sklearn.model_selection import train_test_split\n\n# === Function to perform MiG feature selection === #\ndef apply_mig_selection(csv_path, k=300, output_csv=''):\n    # Load dataset\n    df = pd.read_csv(csv_path)\n\n    # Separate features and labels\n    X = df.drop('Class', axis=1)\n    y = df['Class']\n\n    # Apply MiG using SelectKBest\n    selector = SelectKBest(score_func=mutual_info_classif, k=k)\n    X_selected = selector.fit_transform(X, y)\n\n    # Get selected feature names\n    selected_columns = X.columns[selector.get_support()]\n\n    # Create new DataFrame with selected features + Class\n    selected_df = df[selected_columns]\n    selected_df['Class'] = y  # add class column back\n\n    # Save result\n    if output_csv:\n        selected_df.to_csv(output_csv, index=False)\n        print(f\"Saved selected {k} MiG features to {output_csv}\")\n    \n    return selected_df\n\n# === Apply MiG on both datasets === #\n# Adjust `k` to select top N features as needed\ndf18520_mig = apply_mig_selection('/kaggle/input/GSE18520_processed.csv', k=300,\n                                  output_csv='GSE18520_MiG_selected.csv')\n\ndf26712_mig = apply_mig_selection('/kaggle/input/GSE26712_processed.csv', k=300,\n                                  output_csv='GSE26712_MiG_selected.csv')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# === INPUT FILES ===\nmig_file = \"//kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv\"\nanova_file = \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv\"\nlasso_file = \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv\"\nmrmrsvmrfe_file = \"/kaggle/input/tittititit/combined_top421_common_genes_mrmrsvmrfe.csv\"\n\n# === CLASSIFIER DEFINITIONS ===\nmodels = {\n    \"LR\": LogisticRegression(max_iter=1000),\n    \"RF\": RandomForestClassifier(),\n    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n    \"SVM\": SVC(probability=True)\n}\n\n# === FUNCTION TO RUN MODELS ON A GIVEN FILE ===\ndef evaluate_selected_features(file_path, method_name):\n    df = pd.read_csv(file_path)\n    X = df.drop(columns=['Class'])\n    y = df['Class']\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.4, random_state=90\n    )\n\n    results = []\n    for model_name, model in models.items():\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        y_prob = model.predict_proba(X_test)[:, 1]\n\n        results.append({\n            \"Feature Selection\": method_name,\n            \"Model\": model_name,\n            \"Accuracy\": accuracy_score(y_test, y_pred),\n            \"Precision\": precision_score(y_test, y_pred),\n            \"Recall\": recall_score(y_test, y_pred),\n            \"F1-score\": f1_score(y_test, y_pred),\n            \"AUC\": roc_auc_score(y_test, y_prob)\n        })\n    return results\n\n# === RUN EVALUATION FOR EACH METHOD ===\nall_results = []\nall_results.extend(evaluate_selected_features(mig_file, \"MiG\"))\nall_results.extend(evaluate_selected_features(anova_file, \"ANOVA\"))\nall_results.extend(evaluate_selected_features(lasso_file, \"LASSO\"))\nall_results.extend(evaluate_selected_features(mrmrsvmrfe_file, \"mRMR + SVM-RFE\"))\n\n# === SAVE & DISPLAY RESULTS ===\nresults_df = pd.DataFrame(all_results)\nprint(results_df)\nresults_df.to_csv(\"feature_selection_model_performance.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T22:03:52.100769Z","iopub.execute_input":"2025-08-18T22:03:52.100997Z","iopub.status.idle":"2025-08-18T22:04:01.258682Z","shell.execute_reply.started":"2025-08-18T22:03:52.100975Z","shell.execute_reply":"2025-08-18T22:04:01.257776Z"}},"outputs":[{"name":"stdout","text":"   Feature Selection    Model  Accuracy  Precision  Recall  F1-score  AUC\n0                MiG       LR       1.0        1.0     1.0       1.0  1.0\n1                MiG       RF       1.0        1.0     1.0       1.0  1.0\n2                MiG  XGBoost       1.0        1.0     1.0       1.0  1.0\n3                MiG      SVM       1.0        1.0     1.0       1.0  1.0\n4              ANOVA       LR       1.0        1.0     1.0       1.0  1.0\n5              ANOVA       RF       1.0        1.0     1.0       1.0  1.0\n6              ANOVA  XGBoost       1.0        1.0     1.0       1.0  1.0\n7              ANOVA      SVM       1.0        1.0     1.0       1.0  1.0\n8              LASSO       LR       1.0        1.0     1.0       1.0  1.0\n9              LASSO       RF       1.0        1.0     1.0       1.0  1.0\n10             LASSO  XGBoost       1.0        1.0     1.0       1.0  1.0\n11             LASSO      SVM       1.0        1.0     1.0       1.0  1.0\n12    mRMR + SVM-RFE       LR       1.0        1.0     1.0       1.0  1.0\n13    mRMR + SVM-RFE       RF       1.0        1.0     1.0       1.0  1.0\n14    mRMR + SVM-RFE  XGBoost       1.0        1.0     1.0       1.0  1.0\n15    mRMR + SVM-RFE      SVM       1.0        1.0     1.0       1.0  1.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Edit this cell, aurin","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.utils.class_weight import compute_sample_weight\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score, balanced_accuracy_score\n)\n\n# ========= CONFIG =========\n# Four input files: each must have only selected features + a 'Class' column (0 = normal, 1 = cancer)\ninput_files = {\n    \"MiG\":        \"//kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv\",\n    \"ANOVA\":      \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv\",\n    \"LASSO\":      \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv\",\n    \"mRMR+SVMRFE\":\"/kaggle/input/tittititit/combined_top421_common_genes_mrmrsvmrfe.csv\",\n}\n\n# PCA dims (set to None to disable). With 421 feats & 254 samples, 50‚Äì100 is a good start.\nPCA_COMPONENTS = None\n\n# CV setup\nN_SPLITS = 10\nRANDOM_STATE = 59\nSHUFFLE = True\n\n# ========= MODELS (regularized / small to curb overfitting) =========\ndef make_models():\n    return {\n        \"LogReg\": Pipeline([\n            (\"scaler\", StandardScaler()),\n            *([] if PCA_COMPONENTS is None else [(\"pca\", PCA(n_components=PCA_COMPONENTS, whiten=True, random_state=RANDOM_STATE))]),\n            (\"clf\", LogisticRegression(\n                penalty=\"l2\",          # Regularization type (\"l1\", \"l2\", \"elasticnet\", \"none\")\n                C=0.01,                 # Inverse of regularization strength (smaller ‚Üí stronger regularization)\n                max_iter=5000,         # Max number of iterations (increase if convergence warning appears)\n                solver=\"liblinear\",    # Solver to use (\"liblinear\", \"saga\", \"lbfgs\", \"newton-cg\", \"sag\")\n                multi_class=\"ovr\",     # \"ovr\" = one-vs-rest (good for imbalanced), \"multinomial\" (if many classes)\n                class_weight=\"balanced\" # Balance weights automatically (\"balanced\" or None or custom dict)\n            ))\n        ]),\n\n        \"SigmoidSVM\": Pipeline([\n            (\"scaler\", StandardScaler()),\n            *([] if PCA_COMPONENTS is None else [(\"pca\", PCA(n_components=PCA_COMPONENTS, whiten=True, random_state=RANDOM_STATE))]),\n            (\"clf\", SVC(\n                kernel=\"sigmoid\",    #or use rbf,\n                C=0.01,                 # stronger regularization\n                gamma = \"scale\",     #or use auto\n                probability=True,      # needed for ROC-AUC\n                random_state=RANDOM_STATE\n            ))\n        ]),\n\n        \"RandomForest\": Pipeline([\n            *([] if PCA_COMPONENTS is None else [(\"pca\", PCA(n_components=PCA_COMPONENTS, whiten=False, random_state=RANDOM_STATE))]),\n            (\"clf\", RandomForestClassifier(\n            n_estimators=500,              # try 100, 300, 500, 1000\n            criterion=\"log_loss\",           # try \"gini\", \"entropy\", \"log_loss\"\n            max_depth=3,                  # try None, 5, 10, 20\n            min_samples_split=10,           # try 2, 5, 10\n            min_samples_leaf=10,            # try 1, 2, 4\n            max_features=0.1,           # try \"sqrt\", \"log2\", 0.5, None\n            bootstrap=True,                # try True, False\n            oob_score=True,                # enables out-of-bag validation\n            class_weight=\"balanced\",       # handle imbalance\n            random_state=RANDOM_STATE,\n            n_jobs=-1\n            ))\n        ]),\n\n        \"XGBoost\": Pipeline([\n            *([] if PCA_COMPONENTS is None else [(\"pca\", PCA(n_components=PCA_COMPONENTS, whiten=False, random_state=RANDOM_STATE))]),\n            (\"clf\", XGBClassifier(\n                n_estimators= 300,\n                learning_rate= 0.03,\n                max_depth= 2,\n                subsample= 0.6,\n                colsample_bytree= 0.4,\n                reg_alpha= 5,\n                reg_lambda= 10,\n                min_child_weight= 10,\n                gamma = 5,\n                scale_pos_weight= 12,\n                eval_metric= \"logloss\",\n                random_state=RANDOM_STATE,\n                n_jobs= -1,\n                use_label_encoder= False\n            ))\n        ])\n    }\n\n# ========= CV EVALUATION WITH SAMPLE WEIGHTS =========\ndef cv_eval(df, method_name):\n    assert \"Class\" in df.columns, f\"'Class' column missing in {method_name}\"\n    X = df.drop(columns=[\"Class\"])\n    y = df[\"Class\"].astype(int).values\n\n    # storage for out-of-fold predictions\n    y_pred_oof = {m: np.zeros_like(y) for m in make_models().keys()}\n    y_prob_oof = {m: np.zeros_like(y, dtype=float) for m in make_models().keys()}\n\n    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=SHUFFLE, random_state=RANDOM_STATE)\n\n    for fold, (tr_idx, te_idx) in enumerate(skf.split(X, y), start=1):\n        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n        y_tr, y_te = y[tr_idx], y[te_idx]\n\n        # compute sample weights (higher for minority class, here likely class 0)\n        w_tr = compute_sample_weight(class_weight=\"balanced\", y=y_tr)\n\n        models = make_models()\n        for name, pipe in models.items():\n            # Fit with sample_weight on final estimator inside Pipeline:\n            # pass as 'clf__sample_weight'\n            fit_kwargs = {}\n            try:\n                fit_kwargs = {\"clf__sample_weight\": w_tr}\n            except Exception:\n                fit_kwargs = {}\n\n            pipe.fit(X_tr, y_tr, **fit_kwargs)\n\n            y_pred = pipe.predict(X_te)\n            # predict_proba may be missing on some pipelines if model doesn't support it;\n            # here all do (SVC has probability=True).\n            y_proba = pipe.predict_proba(X_te)[:, 1]\n\n            y_pred_oof[name][te_idx] = y_pred\n            y_prob_oof[name][te_idx] = y_proba\n\n    # aggregate metrics\n    rows = []\n    for name in y_pred_oof.keys():\n        yhat = y_pred_oof[name]\n        yprob = y_prob_oof[name]\n        rows.append({\n            \"Feature Selection\": method_name,\n            \"Model\": name,\n            \"Accuracy\": accuracy_score(y, yhat),\n            \"Precision\": precision_score(y, yhat, zero_division=0),\n            \"Recall\": recall_score(y, yhat, zero_division=0),\n            \"F1-score\": f1_score(y, yhat, zero_division=0),\n            \"AUC\": roc_auc_score(y, yprob)\n        })\n    return pd.DataFrame(rows)\n\n# ========= RUN ALL METHODS =========\nall_results = []\nfor method, path in input_files.items():\n    df = pd.read_csv(path)\n    res = cv_eval(df, method)\n    all_results.append(res)\n\nresults_df = pd.concat(all_results, ignore_index=True)\nprint(results_df)\nresults_df.to_csv(\"PCA=none_feature_selection_model_performance_robust.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:03:08.884900Z","iopub.execute_input":"2025-08-21T07:03:08.885264Z","iopub.status.idle":"2025-08-21T07:04:37.649704Z","shell.execute_reply.started":"2025-08-21T07:03:08.885237Z","shell.execute_reply":"2025-08-21T07:04:37.648747Z"}},"outputs":[{"name":"stdout","text":"   Feature Selection         Model  Accuracy  Precision    Recall  F1-score  \\\n0                MiG        LogReg  0.910853   1.000000  0.903361  0.949227   \n1                MiG    SigmoidSVM  0.860465   1.000000  0.848739  0.918182   \n2                MiG  RandomForest  1.000000   1.000000  1.000000  1.000000   \n3                MiG       XGBoost  0.992248   0.991667  1.000000  0.995816   \n4              ANOVA        LogReg  0.906977   1.000000  0.899160  0.946903   \n5              ANOVA    SigmoidSVM  0.899225   1.000000  0.890756  0.942222   \n6              ANOVA  RandomForest  1.000000   1.000000  1.000000  1.000000   \n7              ANOVA       XGBoost  0.992248   0.991667  1.000000  0.995816   \n8              LASSO        LogReg  0.906977   1.000000  0.899160  0.946903   \n9              LASSO    SigmoidSVM  0.891473   1.000000  0.882353  0.937500   \n10             LASSO  RandomForest  1.000000   1.000000  1.000000  1.000000   \n11             LASSO       XGBoost  0.992248   0.991667  1.000000  0.995816   \n12       mRMR+SVMRFE        LogReg  0.910853   1.000000  0.903361  0.949227   \n13       mRMR+SVMRFE    SigmoidSVM  0.887597   1.000000  0.878151  0.935123   \n14       mRMR+SVMRFE  RandomForest  1.000000   1.000000  1.000000  1.000000   \n15       mRMR+SVMRFE       XGBoost  0.992248   0.991667  1.000000  0.995816   \n\n    AUC  \n0   1.0  \n1   1.0  \n2   1.0  \n3   1.0  \n4   1.0  \n5   1.0  \n6   1.0  \n7   1.0  \n8   1.0  \n9   1.0  \n10  1.0  \n11  1.0  \n12  1.0  \n13  1.0  \n14  1.0  \n15  1.0  \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold, cross_validate\nfrom sklearn.metrics import make_scorer, accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n\n# -----------------------------\n# Define evaluation metrics\n# -----------------------------\nscoring = {\n    'accuracy': make_scorer(accuracy_score),\n    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n    'precision': make_scorer(precision_score, average='weighted'),\n    'recall': make_scorer(recall_score, average='weighted'),\n    'f1': make_scorer(f1_score, average='weighted'),\n    'roc_auc': make_scorer(roc_auc_score, needs_proba=True, average='weighted', multi_class='ovo')\n}\n\n# -----------------------------\n# Random Forest configuration (tuned for small data)\n# -----------------------------\nrf = RandomForestClassifier(\n    n_estimators=200,\n    max_depth=5,\n    min_samples_split=10,\n    min_samples_leaf=5,\n    max_features=0.2,      # 20% of features at each split\n    class_weight='balanced',\n    bootstrap=True,\n    oob_score=False,\n    random_state=90,\n    n_jobs=-1\n)\n\n# -----------------------------\n# Stratified 10-Fold Cross-Validation\n# -----------------------------\ncv = StratifiedKFold(n_splits=20, shuffle=True, random_state=90)\n\n# -----------------------------\n# Function to evaluate a dataset\n# -----------------------------\ndef evaluate_dataset(file_path):\n    data = pd.read_csv(file_path)\n    \n    # Assuming last column is the target\n    X = data.iloc[:, :-1].values\n    y = data.iloc[:, -1].values\n\n    # Perform cross-validation\n    cv_results = cross_validate(rf, X, y, cv=cv, scoring=scoring)\n\n    # Compute mean of each metric\n    metrics_mean = {metric: np.mean(values) for metric, values in cv_results.items() if metric.startswith('test_')}\n    \n    return metrics_mean\n\n# -----------------------------\n# Process all four datasets\n# -----------------------------\nfiles = [\n    '/kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv',\n    '/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv',\n    '/kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv',\n    '/kaggle/input/tittititit/combined_top421_common_genes_mrmrsvmrfe.csv'\n]\n\n\nresults = []\nfor file in files:\n    metrics = evaluate_dataset(file)\n    metrics['Dataset'] = file\n    results.append(metrics)\n\n# -----------------------------\n# Create a summary table\n# -----------------------------\ndf_results = pd.DataFrame(results)\ndf_results = df_results[['Dataset', 'test_accuracy', 'test_balanced_accuracy', 'test_precision', 'test_recall', 'test_f1', 'test_roc_auc']]\n\n# Rename columns for readability\ndf_results.columns = ['Dataset', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC-AUC']\n\nprint(\"\\n===== Cross-Validation Results =====\\n\")\nprint(df_results.to_string(index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T18:15:27.658015Z","iopub.execute_input":"2025-08-20T18:15:27.658434Z","iopub.status.idle":"2025-08-20T18:16:19.002467Z","shell.execute_reply.started":"2025-08-20T18:15:27.658403Z","shell.execute_reply":"2025-08-20T18:16:19.001546Z"}},"outputs":[{"name":"stdout","text":"\n===== Cross-Validation Results =====\n\n                                                                 Dataset  Accuracy  Balanced Accuracy  Precision  Recall  F1-score  ROC-AUC\n  /kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv       1.0                1.0        1.0     1.0       1.0      1.0\n/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv       1.0                1.0        1.0     1.0       1.0      1.0\n/kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv       1.0                1.0        1.0     1.0       1.0      1.0\n    /kaggle/input/tittititit/combined_top421_common_genes_mrmrsvmrfe.csv       1.0                1.0        1.0     1.0       1.0      1.0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.utils.class_weight import compute_sample_weight\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score, balanced_accuracy_score\n)\n\n# ========= CONFIG =========\n# Four input files: each must have only selected features + a 'Class' column (0 = normal, 1 = cancer)\ninput_files = {\n    \"MiG\":        \"//kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv\",\n    \"ANOVA\":      \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv\",\n    \"LASSO\":      \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv\",\n    \"mRMR+SVMRFE\":\"/kaggle/input/tittititit/combined_top421_common_genes_mrmrsvmrfe.csv\",\n}\n\nN_SPLITS = 10\nRANDOM_STATE = 75\nSHUFFLE = True\n\n# ========= MODELS (stronger regularization to reduce overfitting) =========\ndef make_models():\n    return {\n        \"LogReg\": Pipeline([\n            (\"scaler\", StandardScaler()),\n            (\"clf\", LogisticRegression(\n                penalty=\"l2\",\n                C=0.001,               # Stronger regularization (lower C)\n                max_iter=5000,\n                solver=\"liblinear\",\n                multi_class=\"ovr\",\n                class_weight=\"balanced\"\n            ))\n        ]),\n\n        \"SigmoidSVM\": Pipeline([\n            (\"scaler\", StandardScaler()),\n            (\"clf\", SVC(\n                kernel=\"sigmoid\",    #or use rbf,\n                C=0.001,                 # stronger regularization\n                gamma = \"scale\",     #or use auto\n                probability=True,      # needed for ROC-AUC\n                random_state=RANDOM_STATE\n            ))\n        ]),\n\n        \"RandomForest\": Pipeline([\n            (\"clf\", RandomForestClassifier(\n                n_estimators=300,              # Moderate number\n                criterion=\"log_loss\",\n                max_depth=8,                  # Shallower depth\n                min_samples_split=20,           # Higher split threshold\n                min_samples_leaf=15,            # Higher leaf size\n                max_features=0.2,\n                bootstrap=True,\n                oob_score=True,\n                class_weight=\"balanced\",\n                random_state=RANDOM_STATE,\n                n_jobs=-1\n            ))\n        ]),\n\n        \"XGBoost\": Pipeline([\n            (\"clf\", XGBClassifier(\n                n_estimators=200,              # Reduced\n                learning_rate=0.01,            # Slower learning\n                max_depth=3,                   # Shallow\n                subsample=0.5,\n                colsample_bytree=0.3,\n                reg_alpha=10,                  # Stronger L1\n                reg_lambda=15,                 # Stronger L2\n                min_child_weight=15,\n                gamma=10,\n                scale_pos_weight=10,           # Adjusted for ~90/10 imbalance\n                eval_metric=\"logloss\",\n                random_state=RANDOM_STATE,\n                n_jobs=-1,\n                use_label_encoder=False\n            ))\n        ])\n    }\n\n# ========= CV EVALUATION WITH SAMPLE WEIGHTS =========\ndef cv_eval(df, method_name):\n    assert \"Class\" in df.columns, f\"'Class' column missing in {method_name}\"\n    X = df.drop(columns=[\"Class\"])\n    y = df[\"Class\"].astype(int).values\n\n    # storage for out-of-fold predictions\n    models = make_models()\n    y_pred_oof = {m: np.zeros_like(y) for m in models.keys()}\n    y_prob_oof = {m: np.zeros_like(y, dtype=float) for m in models.keys()}\n\n    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=SHUFFLE, random_state=RANDOM_STATE)\n\n    for fold, (tr_idx, te_idx) in enumerate(skf.split(X, y), start=1):\n        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n        y_tr, y_te = y[tr_idx], y[te_idx]\n\n        # compute sample weights\n        w_tr = compute_sample_weight(class_weight=\"balanced\", y=y_tr)\n\n        for name, pipe in models.items():\n            # Pass sample_weight to fit without prefix\n            pipe.fit(X_tr, y_tr, clf__sample_weight=w_tr if 'clf' in pipe.named_steps else None)\n\n            y_pred = pipe.predict(X_te)\n            y_proba = pipe.predict_proba(X_te)[:, 1]\n\n            y_pred_oof[name][te_idx] = y_pred\n            y_prob_oof[name][te_idx] = y_proba\n\n    # aggregate metrics\n    rows = []\n    for name in y_pred_oof.keys():\n        yhat = y_pred_oof[name]\n        yprob = y_prob_oof[name]\n        rows.append({\n            \"Feature Selection\": method_name,\n            \"Model\": name,\n            \"Accuracy\": accuracy_score(y, yhat),\n            \"Precision\": precision_score(y, yhat, zero_division=0),\n            \"Recall\": recall_score(y, yhat, zero_division=0),\n            \"F1-score\": f1_score(y, yhat, zero_division=0),\n            \"AUC\": roc_auc_score(y, yprob)\n        })\n    return pd.DataFrame(rows)\n\n# ========= RUN ALL METHODS =========\nall_results = []\nfor method, path in input_files.items():\n    df = pd.read_csv(path)\n    res = cv_eval(df, method)\n    all_results.append(res)\n\nresults_df = pd.concat(all_results, ignore_index=True)\nprint(results_df)\nresults_df.to_csv(\"feature_selection_model_performance_robust.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T02:06:40.957668Z","iopub.execute_input":"2025-08-23T02:06:40.957938Z","iopub.status.idle":"2025-08-23T02:08:06.129694Z","shell.execute_reply.started":"2025-08-23T02:06:40.957918Z","shell.execute_reply":"2025-08-23T02:08:06.128623Z"}},"outputs":[{"name":"stdout","text":"   Feature Selection         Model  Accuracy  Precision    Recall  F1-score  \\\n0                MiG        LogReg  0.806202   1.000000  0.789916  0.882629   \n1                MiG    SigmoidSVM  0.759690   0.923077  0.806723  0.860987   \n2                MiG  RandomForest  1.000000   1.000000  1.000000  1.000000   \n3                MiG       XGBoost  0.968992   0.967480  1.000000  0.983471   \n4              ANOVA        LogReg  0.833333   1.000000  0.819328  0.900693   \n5              ANOVA    SigmoidSVM  0.759690   0.923077  0.806723  0.860987   \n6              ANOVA  RandomForest  1.000000   1.000000  1.000000  1.000000   \n7              ANOVA       XGBoost  0.968992   0.967480  1.000000  0.983471   \n8              LASSO        LogReg  0.798450   1.000000  0.781513  0.877358   \n9              LASSO    SigmoidSVM  0.759690   0.923077  0.806723  0.860987   \n10             LASSO  RandomForest  1.000000   1.000000  1.000000  1.000000   \n11             LASSO       XGBoost  0.972868   0.971429  1.000000  0.985507   \n12       mRMR+SVMRFE        LogReg  0.810078   1.000000  0.794118  0.885246   \n13       mRMR+SVMRFE    SigmoidSVM  0.759690   0.923077  0.806723  0.860987   \n14       mRMR+SVMRFE  RandomForest  1.000000   1.000000  1.000000  1.000000   \n15       mRMR+SVMRFE       XGBoost  0.968992   0.967480  1.000000  0.983471   \n\n         AUC  \n0   1.000000  \n1   0.154622  \n2   1.000000  \n3   1.000000  \n4   1.000000  \n5   0.154622  \n6   1.000000  \n7   1.000000  \n8   1.000000  \n9   0.154622  \n10  1.000000  \n11  1.000000  \n12  1.000000  \n13  0.154622  \n14  1.000000  \n15  1.000000  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom tabulate import tabulate\n\n# Input files\nfiles = [\n    \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv\",\n    \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv\",\n    \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv\",\n    \"/kaggle/input/tittititit/combined_top421_common_genes_mrmrsvmrfe.csv\"\n]\n\nresults = []\n\n# Outer CV (true evaluation)\nouter_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Hyperparameter grid\nparam_grid = {\n    \"n_estimators\": [100, 200],\n    \"max_depth\": [3, 5, 7, 10],\n    \"max_features\": [\"sqrt\", \"log2\"],\n    \"min_samples_leaf\": [1, 2, 4]\n}\n\nfor file in files:\n    data = pd.read_csv(file)\n    X = data.iloc[:, :-1].values\n    y = data.iloc[:, -1].values\n\n    # Inner CV for tuning\n    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n    rf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n\n    clf = GridSearchCV(rf, param_grid, cv=inner_cv, scoring=\"accuracy\", n_jobs=-1)\n    \n    # Evaluate with outer CV\n    scores = cross_validate(clf, X, y, cv=outer_cv, scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"], n_jobs=-1, return_estimator=True)\n\n    results.append({\n        \"File\": file,\n        \"Acc Mean\": np.mean(scores[\"test_accuracy\"]),\n        \"Acc Std\": np.std(scores[\"test_accuracy\"]),\n        \"Precision\": np.mean(scores[\"test_precision\"]),\n        \"Recall\": np.mean(scores[\"test_recall\"]),\n        \"F1\": np.mean(scores[\"test_f1\"])\n    })\n\n# üìä Display results in table\ndf_results = pd.DataFrame(results)\nprint(tabulate(df_results, headers=\"keys\", tablefmt=\"pretty\", floatfmt=\".4f\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T02:56:22.363188Z","iopub.execute_input":"2025-08-20T02:56:22.363530Z","iopub.status.idle":"2025-08-20T03:06:07.911828Z","shell.execute_reply.started":"2025-08-20T02:56:22.363506Z","shell.execute_reply":"2025-08-20T03:06:07.910863Z"}},"outputs":[{"name":"stdout","text":"+---+--------------------------------------------------------------------------+----------+---------+-----------+--------+-----+\n|   |                                   File                                   | Acc Mean | Acc Std | Precision | Recall | F1  |\n+---+--------------------------------------------------------------------------+----------+---------+-----------+--------+-----+\n| 0 |  /kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv  |   1.0    |   0.0   |    1.0    |  1.0   | 1.0 |\n| 1 | /kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv |   1.0    |   0.0   |    1.0    |  1.0   | 1.0 |\n| 2 | /kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv |   1.0    |   0.0   |    1.0    |  1.0   | 1.0 |\n| 3 |   /kaggle/input/tittititit/combined_top421_common_genes_mrmrsvmrfe.csv   |   1.0    |   0.0   |    1.0    |  1.0   | 1.0 |\n+---+--------------------------------------------------------------------------+----------+---------+-----------+--------+-----+\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"**trying different svm models**","metadata":{}},{"cell_type":"markdown","source":"# new common genes","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the reduced datasets\ngse_18520_reduced = pd.read_csv('/kaggle/input/mrmrsvmrfe/GSE18520_selected_features_svm_rfe.csv')  # Adjust path as needed\ngse_26712_reduced = pd.read_csv('/kaggle/input/mrmrsvmrfe/GSE26712_selected_features_svm_rfe.csv')  # Adjust path as needed\n\n# Extract gene names (all columns except the last one)\ngenes_18520 = set(gse_18520_reduced.columns[:-1])\ngenes_26712 = set(gse_26712_reduced.columns[:-1])\n\n# Find common genes\ncommon_genes = list(genes_18520.intersection(genes_26712))\nnum_common_genes = len(common_genes)\n\nprint(f\"Number of common genes between GSE18520_reduced_anova and GSE26712_reduced_anova: {num_common_genes}\")\n\n# If common genes > 421, select top 421 based on ANOVA F-scores\nif num_common_genes > 421:\n    # Combine datasets to compute ANOVA F-scores on common genes\n    # For GSE 18520\n    X_18520_common = gse_18520_reduced[common_genes]\n    y_18520 = gse_18520_reduced.iloc[:, -1]\n    scaler_18520 = StandardScaler()\n    X_18520_common_scaled = scaler_18520.fit_transform(X_18520_common)\n    \n    # For GSE 26712\n    X_26712_common = gse_26712_reduced[common_genes]\n    y_26712 = gse_26712_reduced.iloc[:, -1]\n    scaler_26712 = StandardScaler()\n    X_26712_common_scaled = scaler_26712.fit_transform(X_26712_common)\n    \n    # Compute ANOVA F-scores (average across both datasets)\n    f_scores_18520, _ = f_classif(X_18520_common_scaled, y_18520)\n    f_scores_26712, _ = f_classif(X_26712_common_scaled, y_26712)\n    f_scores_avg = (f_scores_18520 + f_scores_26712) / 2\n    \n    # Get indices of top 421 common genes\n    top_common_idx = np.argsort(f_scores_avg)[-421:]\n    top_common_genes = [common_genes[i] for i in top_common_idx]\n    \n    # Create new dataset with top 421 common genes (using GSE 18520 as base)\n    common_genes_df = gse_18520_reduced[top_common_genes + [gse_18520_reduced.columns[-1]]]\n    \n    # Save to CSV\n    common_genes_df.to_csv('common_genes_mrmrsvmrfe.csv', index=False)\n    print(f\"Saved top 421 common genes to 'common_genes_mrmr.csv' with {common_genes_df.shape[0]} samples.\")\nelse:\n    print(\"Number of common genes is less than or equal to 421. No new CSV file generated.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:18:49.203670Z","iopub.execute_input":"2025-08-21T17:18:49.203996Z","iopub.status.idle":"2025-08-21T17:18:49.316076Z","shell.execute_reply.started":"2025-08-21T17:18:49.203976Z","shell.execute_reply":"2025-08-21T17:18:49.315250Z"}},"outputs":[{"name":"stdout","text":"Number of common genes between GSE18520_reduced_anova and GSE26712_reduced_anova: 421\nNumber of common genes is less than or equal to 421. No new CSV file generated.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#selecting the 421 common genes among the previous two results\nimport pandas as pd\nfrom sklearn.feature_selection import mutual_info_classif\nimport numpy as np\n\n# Load the reduced datasets\ngse_18520_reduced = pd.read_csv('/kaggle/input/mig-anova-lasso-selection/MiG selection/MiG_selected_1290_features_GSE26712.csv')  # Adjust path as needed\ngse_26712_reduced = pd.read_csv('/kaggle/input/mig-anova-lasso-selection/MiG selection/MiG_selected_3620_features_GSE18520.csv')  # Adjust path as needed\n\n# Extract gene names (all columns except the last one)\ngenes_18520 = set(gse_18520_reduced.columns[:-1])\ngenes_26712 = set(gse_26712_reduced.columns[:-1])\n\n# Find common genes\ncommon_genes = list(genes_18520.intersection(genes_26712))\nnum_common_genes = len(common_genes)\n\nprint(f\"Number of common genes between GSE18520_reduced and GSE26712_reduced: {num_common_genes}\")\n\n# If common genes > 421, select top 421 based on mutual information\nif num_common_genes > 421:\n    # Combine datasets to compute MI on common genes\n    # For GSE 18520\n    X_18520_common = gse_18520_reduced[common_genes]\n    y_18520 = gse_18520_reduced.iloc[:, -1]\n    \n    # For GSE 26712\n    X_26712_common = gse_26712_reduced[common_genes]\n    y_26712 = gse_26712_reduced.iloc[:, -1]\n    \n    # Compute MI scores for common genes (average MI across both datasets)\n    mi_scores_18520 = mutual_info_classif(X_18520_common, y_18520, random_state=42)\n    mi_scores_26712 = mutual_info_classif(X_26712_common, y_26712, random_state=42)\n    mi_scores_avg = (mi_scores_18520 + mi_scores_26712) / 2\n    \n    # Get indices of top 421 common genes\n    top_common_idx = np.argsort(mi_scores_avg)[-421:]\n    top_common_genes = [common_genes[i] for i in top_common_idx]\n    \n    # Create new dataset with top 421 common genes (using GSE 18520 as base, can use 26712 if preferred)\n    common_genes_df = gse_18520_reduced[top_common_genes + [gse_18520_reduced.columns[-1]]]\n    \n    # Save to CSV\n    common_genes_df.to_csv('new_common_genes_mig.csv', index=False)\n    print(f\"Saved top 421 common genes to 'common_genes_mig.csv' with {common_genes_df.shape[0]} samples.\")\nelse:\n    print(\"Number of common genes is less than or equal to 421. No new CSV file generated.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:32:04.850829Z","iopub.execute_input":"2025-08-21T17:32:04.851078Z","iopub.status.idle":"2025-08-21T17:32:06.088490Z","shell.execute_reply.started":"2025-08-21T17:32:04.851061Z","shell.execute_reply":"2025-08-21T17:32:06.087777Z"}},"outputs":[{"name":"stdout","text":"Number of common genes between GSE18520_reduced and GSE26712_reduced: 433\nSaved top 421 common genes to 'common_genes_mig.csv' with 195 samples.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Check shape","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# File paths\nfile1_path = \"/kaggle/input/aurin-common-gene-code-result/common_genes_anova (1) from aurin.csv\"\nfile2_path = \"/kaggle/input/aurin-common-gene-code-result/common_genes_mig (1) from aurin.csv\"\nfile3_path = \"/kaggle/input/aurin-common-gene-code-result/common_genes_anova.csv\"\nfile4_path = \"/kaggle/input/aurin-common-gene-code-result/common_genes_lasso.csv\"\nfile5_path = \"/kaggle/input/aurin-common-gene-code-result/common_genes_mig.csv\"\nfile6_path = \"/kaggle/working/new_common_genes_mig.csv\"\n\n# Load CSV files\ndf1 = pd.read_csv(file1_path)\ndf2 = pd.read_csv(file2_path)\ndf3 = pd.read_csv(file3_path)\ndf4 = pd.read_csv(file4_path)\ndf5 = pd.read_csv(file5_path)\ndf6 = pd.read_csv(file6_path)\n\n# Print shapes\nprint(df1.shape)\nprint(df2.shape)\nprint(df3.shape)\nprint(df4.shape)\nprint(df5.shape)\nprint(df6.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:33:17.959998Z","iopub.execute_input":"2025-08-21T17:33:17.960286Z","iopub.status.idle":"2025-08-21T17:33:18.045573Z","shell.execute_reply.started":"2025-08-21T17:33:17.960267Z","shell.execute_reply":"2025-08-21T17:33:18.044829Z"}},"outputs":[{"name":"stdout","text":"(63, 422)\n(63, 422)\n(195, 422)\n(195, 422)\n(195, 422)\n(195, 422)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# Input files (features + target column inside each CSV)\ninput_files = {\n    \"MiG\":        \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv\",\n    \"ANOVA\":      \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv\",\n    \"LASSO\":      \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv\",\n    \"mRMR+SVMRFE\":\"/kaggle/input/tittititit/combined_top421_common_genes_mrmrsvmrfe.csv\",\n}\n\n# Kernels & their tunable parameters\nsvm_models = {\n    \"PolySVM\":    {\"kernel\": \"poly\",    \"C\": [0.01, 0.1, 1], \"degree\": [2, 3, 4], \"gamma\": [\"scale\", \"auto\"]},\n    \"RBFSVM\":     {\"kernel\": \"rbf\",     \"C\": [0.01, 0.1, 1, 10], \"gamma\": [\"scale\", \"auto\"]},\n    \"SigmoidSVM\": {\"kernel\": \"sigmoid\", \"C\": [0.01, 0.1, 1, 10], \"gamma\": [\"scale\", \"auto\"]},\n}\n\nresults = []\n\nfor dataset_name, filepath in input_files.items():\n    df = pd.read_csv(filepath)\n    \n    # Assume last column = target (adjust if named differently)\n    X = df.drop(columns=[\"Class\"])\n    y = df[\"Class\"]\n\n    # Split train/test\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, stratify=y, random_state=42\n    )\n\n    for model_name, params in svm_models.items():\n        # For simplicity, run only with one set of params here \n        # (You can loop over param grid later for tuning)\n        clf = Pipeline([\n            (\"scaler\", StandardScaler()),\n            (\"clf\", SVC(\n                kernel=params[\"kernel\"],\n                C=params.get(\"C\", [0])[0],\n                degree=params.get(\"degree\", [2])[0],\n                gamma=params.get(\"gamma\", [\"scale\"])[0],\n                probability=True,\n                random_state=75\n            ))\n        ])\n\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        y_proba = clf.predict_proba(X_test)[:, 1]\n\n        results.append({\n            \"Dataset\": dataset_name,\n            \"Model\": model_name,\n            \"Accuracy\": accuracy_score(y_test, y_pred),\n            \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n            \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n            \"F1\": f1_score(y_test, y_pred, zero_division=0),\n            \"AUC\": roc_auc_score(y_test, y_proba)\n        })\n\n# Convert to table\nresults_df = pd.DataFrame(results)\nprint(results_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T22:41:54.027715Z","iopub.execute_input":"2025-08-18T22:41:54.028955Z","iopub.status.idle":"2025-08-18T22:41:54.874426Z","shell.execute_reply.started":"2025-08-18T22:41:54.028915Z","shell.execute_reply":"2025-08-18T22:41:54.873279Z"}},"outputs":[{"name":"stdout","text":"        Dataset       Model  Accuracy  Precision  Recall        F1       AUC\n0           MiG   LinearSVM  1.000000   1.000000     1.0  1.000000  1.000000\n1           MiG     PolySVM  1.000000   1.000000     1.0  1.000000  1.000000\n2           MiG      RBFSVM  0.923077   0.923077     1.0  0.960000  1.000000\n3           MiG  SigmoidSVM  0.923077   0.923077     1.0  0.960000  0.979167\n4         ANOVA   LinearSVM  1.000000   1.000000     1.0  1.000000  1.000000\n5         ANOVA     PolySVM  1.000000   1.000000     1.0  1.000000  1.000000\n6         ANOVA      RBFSVM  0.923077   0.923077     1.0  0.960000  1.000000\n7         ANOVA  SigmoidSVM  0.923077   0.923077     1.0  0.960000  0.979167\n8         LASSO   LinearSVM  1.000000   1.000000     1.0  1.000000  1.000000\n9         LASSO     PolySVM  0.942308   0.941176     1.0  0.969697  1.000000\n10        LASSO      RBFSVM  0.923077   0.923077     1.0  0.960000  1.000000\n11        LASSO  SigmoidSVM  0.923077   0.923077     1.0  0.960000  1.000000\n12  mRMR+SVMRFE   LinearSVM  1.000000   1.000000     1.0  1.000000  1.000000\n13  mRMR+SVMRFE     PolySVM  1.000000   1.000000     1.0  1.000000  1.000000\n14  mRMR+SVMRFE      RBFSVM  0.923077   0.923077     1.0  0.960000  1.000000\n15  mRMR+SVMRFE  SigmoidSVM  0.923077   0.923077     1.0  0.960000  1.000000\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, cross_val_predict\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\n# -----------------------------\n# 1Ô∏è‚É£ Load feature-selected datasets\n# -----------------------------\nfiles = {\n    \"MiG\": \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv\",\n    \"ANOVA\": \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv\",\n    \"LASSO\": \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv\",\n    \"mRMR + SVM-RFE\": \"/kaggle/input/tittititit/combined_top421_common_genes_mrmrsvmrfe.csv\"\n}\n\ndatasets = {name: pd.read_csv(path) for name, path in files.items()}\n\n# -----------------------------\n# 2Ô∏è‚É£ Define classifiers with class weight for imbalance\n# -----------------------------\nmodels = {\n    \"SVM\": SVC(kernel=\"linear\", probability=True, class_weight='balanced', random_state=42),\n    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=3, class_weight='balanced', random_state=42),\n    \"XGBoost\": XGBClassifier(eval_metric='logloss', max_depth=3, \n                             scale_pos_weight=(238/20), random_state=42),  # adjust ratio\n    \"Logistic Regression\": LogisticRegression(C=0.01, max_iter=1000, class_weight='balanced', random_state=42)\n}\n\n# -----------------------------\n# 3Ô∏è‚É£ PCA for dimensionality reduction\n# -----------------------------\npca = PCA(n_components=.99)  # retain 95% variance\n\n# -----------------------------\n# 4Ô∏è‚É£ 5-fold stratified CV\n# -----------------------------\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\nresults = []\n\n# -----------------------------\n# 5Ô∏è‚É£ Iterate over each feature selection dataset\n# -----------------------------\nfor fs_name, df in datasets.items():\n    X = df.drop(columns=['Class'])\n    y = df['Class']\n\n    for model_name, model in models.items():\n        # Pipeline: StandardScaler + PCA + Classifier\n        pipeline = make_pipeline(StandardScaler(), pca, model)\n        \n        # Stratified cross-validation predictions\n        y_pred = cross_val_predict(pipeline, X, y, cv=skf, method='predict')\n        y_prob = cross_val_predict(pipeline, X, y, cv=skf, method='predict_proba')[:, 1]\n\n        # Collect metrics\n        results.append({\n            \"Feature Selection\": fs_name,\n            \"Model\": model_name,\n            \"Accuracy\": accuracy_score(y, y_pred),\n            \"Precision\": precision_score(y, y_pred, zero_division=0),\n            \"Recall\": recall_score(y, y_pred),\n            \"F1-score\": f1_score(y, y_pred),\n            \"AUC\": roc_auc_score(y, y_prob)\n        })\n\n# -----------------------------\n# 6Ô∏è‚É£ Display and save results\n# -----------------------------\nresults_df = pd.DataFrame(results)\nprint(results_df)\nresults_df.to_csv(\"pca_.99_2_feature_selection_model_performance_no_smote.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T21:15:52.571105Z","iopub.execute_input":"2025-08-14T21:15:52.571410Z","iopub.status.idle":"2025-08-14T21:17:09.006861Z","shell.execute_reply.started":"2025-08-14T21:15:52.571387Z","shell.execute_reply":"2025-08-14T21:17:09.006008Z"}},"outputs":[{"name":"stdout","text":"   Feature Selection                Model  Accuracy  Precision  Recall  \\\n0                MiG                  SVM  1.000000   1.000000     1.0   \n1                MiG        Random Forest  0.992248   0.991667     1.0   \n2                MiG              XGBoost  0.996124   0.995816     1.0   \n3                MiG  Logistic Regression  1.000000   1.000000     1.0   \n4              ANOVA                  SVM  1.000000   1.000000     1.0   \n5              ANOVA        Random Forest  0.968992   0.967480     1.0   \n6              ANOVA              XGBoost  0.996124   0.995816     1.0   \n7              ANOVA  Logistic Regression  1.000000   1.000000     1.0   \n8              LASSO                  SVM  1.000000   1.000000     1.0   \n9              LASSO        Random Forest  0.968992   0.967480     1.0   \n10             LASSO              XGBoost  0.996124   0.995816     1.0   \n11             LASSO  Logistic Regression  1.000000   1.000000     1.0   \n12    mRMR + SVM-RFE                  SVM  1.000000   1.000000     1.0   \n13    mRMR + SVM-RFE        Random Forest  0.988372   0.987552     1.0   \n14    mRMR + SVM-RFE              XGBoost  0.996124   0.995816     1.0   \n15    mRMR + SVM-RFE  Logistic Regression  1.000000   1.000000     1.0   \n\n    F1-score       AUC  \n0   1.000000  1.000000  \n1   0.995816  1.000000  \n2   0.997904  0.999790  \n3   1.000000  1.000000  \n4   1.000000  1.000000  \n5   0.983471  1.000000  \n6   0.997904  0.999685  \n7   1.000000  1.000000  \n8   1.000000  1.000000  \n9   0.983471  0.999790  \n10  0.997904  0.999685  \n11  1.000000  1.000000  \n12  1.000000  1.000000  \n13  0.993737  1.000000  \n14  0.997904  1.000000  \n15  1.000000  1.000000  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\n# -------------------\n# 1. Train/Test split\n# -------------------\n# X = your features (NumPy array), y = your labels\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)\n\n# -------------------\n# 2. Preprocessing\n# -------------------\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# -------------------\n# 3. PCA (optional)\n# -------------------\npca = PCA(n_components=0.95)  # keep 95% variance\nX_train_pca = pca.fit_transform(X_train_scaled)\nX_test_pca = pca.transform(X_test_scaled)\n\n# -------------------\n# 4. Cross-validation on training set\n# -------------------\nclf = RandomForestClassifier(random_state=42)\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\ny_train_pred_cv = cross_val_predict(clf, X_train_pca, y_train, cv=cv)\nprint(\"Cross-validation performance (training set only):\")\nprint(classification_report(y_train, y_train_pred_cv))\n\n# -------------------\n# 5. Train on full training set & evaluate on test set\n# -------------------\nclf.fit(X_train_pca, y_train)\ny_test_pred = clf.predict(X_test_pca)\n\nprint(\"Final performance on hold-out test set:\")\nprint(classification_report(y_test, y_test_pred))\nprint(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T21:18:30.368127Z","iopub.execute_input":"2025-08-14T21:18:30.368794Z","iopub.status.idle":"2025-08-14T21:18:31.490188Z","shell.execute_reply.started":"2025-08-14T21:18:30.368764Z","shell.execute_reply":"2025-08-14T21:18:31.489291Z"}},"outputs":[{"name":"stdout","text":"Cross-validation performance (training set only):\n              precision    recall  f1-score   support\n\n           0       1.00      0.81      0.90        16\n           1       0.98      1.00      0.99       190\n\n    accuracy                           0.99       206\n   macro avg       0.99      0.91      0.94       206\nweighted avg       0.99      0.99      0.98       206\n\nFinal performance on hold-out test set:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         4\n           1       1.00      1.00      1.00        48\n\n    accuracy                           1.00        52\n   macro avg       1.00      1.00      1.00        52\nweighted avg       1.00      1.00      1.00        52\n\nTest Accuracy: 1.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\n# Step 1: Load both datasets\ndf1 = pd.read_csv(\"/kaggle/input/mrmrsvmrfe/GSE18520_selected_features_svm_rfe.csv\")   # shape (25, 1001)\ndf2 = pd.read_csv(\"/kaggle/input/mrmrsvmrfe/GSE26712_selected_features_svm_rfe.csv\")\n\nprint(df1.shape)\nprint(df2.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T17:15:21.231349Z","iopub.execute_input":"2025-08-21T17:15:21.231607Z","iopub.status.idle":"2025-08-21T17:15:21.381724Z","shell.execute_reply.started":"2025-08-21T17:15:21.231589Z","shell.execute_reply":"2025-08-21T17:15:21.380850Z"}},"outputs":[{"name":"stdout","text":"(63, 3621)\n(195, 1291)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\n# File paths\nfile1_path = \"/kaggle/input/mrmrsvmrfe/GSE18520_selected_features_svm_rfe.csv\"\nfile2_path = \"/kaggle/input/mrmrsvmrfe/GSE26712_selected_features_svm_rfe.csv\"\n\n# Load CSV files\ndf1 = pd.read_csv(file1_path)\ndf2 = pd.read_csv(file2_path)\n\n# Print shapes\nprint(df1.shape)\nprint(df2.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T16:20:18.052979Z","iopub.execute_input":"2025-08-13T16:20:18.053300Z","iopub.status.idle":"2025-08-13T16:20:18.331340Z","shell.execute_reply.started":"2025-08-13T16:20:18.053271Z","shell.execute_reply":"2025-08-13T16:20:18.330360Z"}},"outputs":[{"name":"stdout","text":"(63, 3621)\n(195, 1291)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import pandas as pd\n\n# Step 1: Load both datasets\ndf1 = pd.read_csv(\"/kaggle/input/mrmrsvmrfe/GSE26712_selected_features_svm_rfe.csv\")   # shape (25, 1001)\ndf2 = pd.read_csv(\"/kaggle/input/mrmrsvmrfe/GSE18520_selected_features_svm_rfe.csv\")  # shape (20, 1000)\n\n# Step 2: Extract gene columns (excluding 'Class')\ngenes1 = set(df1.columns) - {\"Class\"}\ngenes2 = set(df2.columns) - {\"Class\"}\n\n# Step 3: Find common genes\ncommon_genes = list(genes1.intersection(genes2))\n\n# Step 4: Select top 87 common genes (sorted for consistency)\ntop_421_genes = sorted(common_genes)[:421]  \n\n# Step 5: Extract top 87 genes + 'Class' from each dataset\ndf1_selected = df1[top_421_genes + [\"Class\"]]\ndf2_selected = df2[top_421_genes + [\"Class\"]]\n\n# Step 6: Combine datasets\ncombined_df = pd.concat([df1_selected, df2_selected], axis=0, ignore_index=True)\n\n# Step 7: Final check\nprint(\"Combined shape:\", combined_df.shape)  # Should be (45, 88)\n\n# Optional: Save combined dataset\ncombined_df.to_csv(\"combined_top421_common_genes_mrmrsvmrfe.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T16:20:52.787417Z","iopub.execute_input":"2025-08-13T16:20:52.788060Z","iopub.status.idle":"2025-08-13T16:20:53.136300Z","shell.execute_reply.started":"2025-08-13T16:20:52.788033Z","shell.execute_reply":"2025-08-13T16:20:53.135315Z"}},"outputs":[{"name":"stdout","text":"Combined shape: (258, 422)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n)\n\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\n# Step 1: Load combined dataset\ndf = pd.read_csv(\"/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv\")\n\n# Step 2: Separate features and target\nX = df.drop(columns=[\"Class\"])\ny = df[\"Class\"]  # Already encoded as 0 or 1 ‚Üí no need for LabelEncoder\n\n# Step 3: Define models with overfitting control\nmodels = {\n    \"SVM\": SVC(kernel=\"linear\", C=0.003, probability=True),\n    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=3,),\n    \"XGBoost\": XGBClassifier(eval_metric='logloss',\n                         max_depth=3, subsample=0.7, reg_alpha=1),\n    \"Logistic Regression\": LogisticRegression(C=0.0045, max_iter=1000)\n}\n\n# Step 4: 5-fold stratified cross-validation evaluation\nskf = StratifiedKFold(n_splits=5, shuffle=True)\n\nfor name, model in models.items():\n    print(f\"\\nüîç {name} Performance (5-fold CV):\")\n    \n    pipe = make_pipeline(StandardScaler(), model)\n    y_pred = cross_val_predict(pipe, X, y, cv=skf, method='predict')\n    y_prob = cross_val_predict(pipe, X, y, cv=skf, method='predict_proba')[:, 1]\n\n    print(f\"Accuracy:  {accuracy_score(y, y_pred):.4f}\")\n    print(f\"Precision: {precision_score(y, y_pred, zero_division=0):.4f}\")\n    print(f\"Recall:    {recall_score(y, y_pred):.4f}\")\n    print(f\"F1 Score:  {f1_score(y, y_pred):.4f}\")\n    print(f\"AUC-ROC:   {roc_auc_score(y, y_prob):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:38:40.955214Z","iopub.execute_input":"2025-08-12T16:38:40.955506Z","iopub.status.idle":"2025-08-12T16:38:46.516531Z","shell.execute_reply.started":"2025-08-12T16:38:40.955487Z","shell.execute_reply":"2025-08-12T16:38:46.515816Z"}},"outputs":[{"name":"stdout","text":"\nüîç SVM Performance (5-fold CV):\nAccuracy:  1.0000\nPrecision: 1.0000\nRecall:    1.0000\nF1 Score:  1.0000\nAUC-ROC:   1.0000\n\nüîç Random Forest Performance (5-fold CV):\nAccuracy:  1.0000\nPrecision: 1.0000\nRecall:    1.0000\nF1 Score:  1.0000\nAUC-ROC:   1.0000\n\nüîç XGBoost Performance (5-fold CV):\nAccuracy:  0.9961\nPrecision: 0.9958\nRecall:    1.0000\nF1 Score:  0.9979\nAUC-ROC:   1.0000\n\nüîç Logistic Regression Performance (5-fold CV):\nAccuracy:  1.0000\nPrecision: 1.0000\nRecall:    1.0000\nF1 Score:  1.0000\nAUC-ROC:   1.0000\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, cross_val_predict\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\n# Step 1: Load combined dataset\ndf = pd.read_csv(\"/kaggle/working/combined_top421_common_genes_mrmrsvmrfe.csv\")\n\n# Step 2: Separate features and target\nX = df.drop(columns=[\"Class\"])\ny = df[\"Class\"]\n\n# Step 3: Define models with overfitting control & class balancing\nmodels = {\n    \"SVM\": SVC(kernel=\"linear\", C=0.001, probability=True, class_weight=\"balanced\"),\n    \"Random Forest\": RandomForestClassifier(\n        n_estimators=100,\n        max_depth=3,\n        max_features=\"sqrt\",\n        class_weight=\"balanced_subsample\",\n        random_state=42\n    ),\n    \"XGBoost\": XGBClassifier(\n        eval_metric='logloss',\n        max_depth=3,\n        subsample=0.7,\n        colsample_bytree=0.8,\n        reg_alpha=2,\n        reg_lambda=2,\n        scale_pos_weight=(y.value_counts()[0] / y.value_counts()[1]),\n        random_state=42\n    ),\n    \"Logistic Regression\": LogisticRegression(\n        C=0.001,\n        max_iter=1000,\n        class_weight=\"balanced\",\n        random_state=42\n    )\n}\n\n# Step 4: Stratified 5-fold CV evaluation\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor name, model in models.items():\n    print(f\"\\nüîç {name} Performance (5-fold CV):\")\n    \n    pipe = make_pipeline(StandardScaler(), model)\n    y_pred = cross_val_predict(pipe, X, y, cv=skf, method='predict')\n    y_prob = cross_val_predict(pipe, X, y, cv=skf, method='predict_proba')[:, 1]\n\n    print(f\"Accuracy:  {accuracy_score(y, y_pred):.4f}\")\n    print(f\"Precision: {precision_score(y, y_pred, zero_division=0):.4f}\")\n    print(f\"Recall:    {recall_score(y, y_pred):.4f}\")\n    print(f\"F1 Score:  {f1_score(y, y_pred):.4f}\")\n    print(f\"AUC-ROC:   {roc_auc_score(y, y_prob):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T16:21:37.065683Z","iopub.execute_input":"2025-08-13T16:21:37.066397Z","iopub.status.idle":"2025-08-13T16:21:43.118238Z","shell.execute_reply.started":"2025-08-13T16:21:37.066373Z","shell.execute_reply":"2025-08-13T16:21:43.117396Z"}},"outputs":[{"name":"stdout","text":"\nüîç SVM Performance (5-fold CV):\nAccuracy:  1.0000\nPrecision: 1.0000\nRecall:    1.0000\nF1 Score:  1.0000\nAUC-ROC:   1.0000\n\nüîç Random Forest Performance (5-fold CV):\nAccuracy:  1.0000\nPrecision: 1.0000\nRecall:    1.0000\nF1 Score:  1.0000\nAUC-ROC:   1.0000\n\nüîç XGBoost Performance (5-fold CV):\nAccuracy:  0.9845\nPrecision: 0.9835\nRecall:    1.0000\nF1 Score:  0.9917\nAUC-ROC:   0.9989\n\nüîç Logistic Regression Performance (5-fold CV):\nAccuracy:  1.0000\nPrecision: 1.0000\nRecall:    1.0000\nF1 Score:  1.0000\nAUC-ROC:   1.0000\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Aurin's code\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Applying classifiers(LR, RF, XGBoost, SVM)\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/working/combined_top421_common_genes_mrmrsvmrfe.csv')\n\n# Separate features and labels\nX = data.iloc[:, :-1]  # All columns except the last one (class)\ny = data.iloc[:, -1]   # Last column (class: 0 or 1)\n\n# Perform stratified train-test split (80-20)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Calculate class weights for imbalanced dataset\nclass_ratio = (y_train == 0).sum() / (y_train == 1).sum()  # Ratio of negative to positive class\n\n# Initialize classifiers with class weighting\nclassifiers = {\n    'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=100),\n    'XGBoost': XGBClassifier(scale_pos_weight=class_ratio, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n    'SVM': SVC(class_weight='balanced', random_state=42, probability=True)\n}\n\n# Initialize results storage\nresults = {\n    'Classifier': [],\n    'Accuracy': [],\n    'Precision': [],\n    'Recall': [],\n    'F1-Score': [],\n    'AUC-ROC': []\n}\n\n# Perform 5-fold stratified cross-validation and evaluate on test set\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nprint(\"for mRMR+SVM_RFE feature selection:\")\n\nfor name, clf in classifiers.items():\n    # Cross-validation on training set (for robustness)\n    cv_scores = cross_val_score(clf, X_train_scaled, y_train, cv=skf, scoring='f1')\n    print(f\"{name} CV F1-Score: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n    \n    # Train on full training set\n    clf.fit(X_train_scaled, y_train)\n    \n    # Predict on test set\n    y_pred = clf.predict(X_test_scaled)\n    y_proba = clf.predict_proba(X_test_scaled)[:, 1] if hasattr(clf, 'predict_proba') else clf.decision_function(X_test_scaled)\n    \n    # Compute metrics\n    results['Classifier'].append(name)\n    results['Accuracy'].append(accuracy_score(y_test, y_pred))\n    results['Precision'].append(precision_score(y_test, y_pred, zero_division=0))\n    results['Recall'].append(recall_score(y_test, y_pred))\n    results['F1-Score'].append(f1_score(y_test, y_pred))\n    results['AUC-ROC'].append(roc_auc_score(y_test, y_proba))\n\n# Create results table\nresults_df = pd.DataFrame(results)\nresults_df = results_df.round(4)  # Round to 4 decimal places for readability\n\n# Save results as a markdown table\nmarkdown_table = results_df.to_markdown(index=False)\n\n# Print and save the table\nprint(\"\\nClassifier Performance Metrics on Test Set:\")\nprint(markdown_table)\n\n# Save the table to a file\nwith open('classifier_metrics.md', 'w') as f:\n    f.write(\"# Classifier Performance Metrics\\n\")\n    f.write(markdown_table)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T16:22:12.290368Z","iopub.execute_input":"2025-08-13T16:22:12.290666Z","iopub.status.idle":"2025-08-13T16:22:15.054529Z","shell.execute_reply.started":"2025-08-13T16:22:12.290647Z","shell.execute_reply":"2025-08-13T16:22:15.053780Z"}},"outputs":[{"name":"stdout","text":"for mRMR+SVM_RFE feature selection:\nLogistic Regression CV F1-Score: 1.0000 ¬± 0.0000\nRandom Forest CV F1-Score: 1.0000 ¬± 0.0000\nXGBoost CV F1-Score: 0.9974 ¬± 0.0052\nSVM CV F1-Score: 1.0000 ¬± 0.0000\n\nClassifier Performance Metrics on Test Set:\n| Classifier          |   Accuracy |   Precision |   Recall |   F1-Score |   AUC-ROC |\n|:--------------------|-----------:|------------:|---------:|-----------:|----------:|\n| Logistic Regression |     1      |        1    |        1 |     1      |      1    |\n| Random Forest       |     1      |        1    |        1 |     1      |      1    |\n| XGBoost             |     0.9615 |        0.96 |        1 |     0.9796 |      0.75 |\n| SVM                 |     1      |        1    |        1 |     1      |      1    |\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"chatgpt polished","metadata":{}},{"cell_type":"code","source":"#with cross & pca=0.95\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv')\n\n# Separate features and labels\nX = data.iloc[:, :-1]  # All columns except the last one (class)\ny = data.iloc[:, -1]   # Last column (class: 0 or 1)\n\n# Apply PCA with 95% variance retention\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\npca = PCA(n_components=0.99)\nX_pca = pca.fit_transform(X_scaled)\nprint(f\"Number of components selected: {pca.n_components_}\")\nprint(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_):.4f}\")\n\n# Initialize classifiers with class weighting\nclass_ratio = (y == 0).sum() / (y == 1).sum()  # Ratio of negative to positive class\nclassifiers = {\n    'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=100),\n    'XGBoost': XGBClassifier(scale_pos_weight=class_ratio, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n    'SVM': SVC(class_weight='balanced', random_state=42, probability=True)\n}\n\n# Initialize results storage\nresults = {\n    'Classifier': [],\n    'Accuracy': [],\n    'Precision': [],\n    'Recall': [],\n    'F1-Score': [],\n    'AUC-ROC': []\n}\n\n# Perform 5-fold stratified cross-validation\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor name, clf in classifiers.items():\n    # Lists to store metrics for each fold\n    acc_scores, prec_scores, rec_scores, f1_scores, auc_scores = [], [], [], [], []\n    \n    # Cross-validation loop\n    for train_idx, test_idx in skf.split(X_pca, y):  # Use X_pca here\n        # Split data\n        X_train, X_test = X_pca[train_idx], X_pca[test_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n        \n        # Scale features (already handled by PCA, but reapply if needed)\n        scaler = StandardScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_test_scaled = scaler.transform(X_test)\n        \n        # Train classifier\n        clf.fit(X_train_scaled, y_train)\n        \n        # Predict on test fold\n        y_pred = clf.predict(X_test_scaled)\n        y_proba = clf.predict_proba(X_test_scaled)[:, 1] if hasattr(clf, 'predict_proba') else clf.decision_function(X_test_scaled)\n        \n        # Compute metrics\n        acc_scores.append(accuracy_score(y_test, y_pred))\n        prec_scores.append(precision_score(y_test, y_pred, zero_division=0))\n        rec_scores.append(recall_score(y_test, y_pred))\n        f1_scores.append(f1_score(y_test, y_pred))\n        auc_scores.append(roc_auc_score(y_test, y_proba))\n    \n    # Store mean of metrics\n    results['Classifier'].append(name)\n    results['Accuracy'].append(np.mean(acc_scores))\n    results['Precision'].append(np.mean(prec_scores))\n    results['Recall'].append(np.mean(rec_scores))\n    results['F1-Score'].append(np.mean(f1_scores))\n    results['AUC-ROC'].append(np.mean(auc_scores))\n    \n    print(f\"{name} CV Metrics:\")\n    print(f\"Accuracy: {np.mean(acc_scores):.4f}\")\n    print(f\"Precision: {np.mean(prec_scores):.4f}\")\n    print(f\"Recall: {np.mean(rec_scores):.4f}\")\n    print(f\"F1-Score: {np.mean(f1_scores):.4f}\")\n    print(f\"AUC-ROC: {np.mean(auc_scores):.4f}\")\n\n# Create results table\nresults_df = pd.DataFrame(results)\nresults_df = results_df.round(4)  # Round to 4 decimal places for readability\n\n# Save results as a markdown table\nmarkdown_table = results_df.to_markdown(index=False)\n\n# Print and save the table\nprint(\"\\nClassifier Performance Metrics (5-Fold CV with PCA):\")\nprint(markdown_table)\n\n# Save the table to a file\nresults_df = pd.DataFrame(results)\nprint(results_df)\nresults_df.to_csv(\"mig performance\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T14:34:11.158654Z","iopub.execute_input":"2025-08-15T14:34:11.159121Z","iopub.status.idle":"2025-08-15T14:34:13.497699Z","shell.execute_reply.started":"2025-08-15T14:34:11.159080Z","shell.execute_reply":"2025-08-15T14:34:13.496537Z"}},"outputs":[{"name":"stdout","text":"Number of components selected: 174\nExplained variance ratio: 0.9901\nLogistic Regression CV Metrics:\nAccuracy: 1.0000\nPrecision: 1.0000\nRecall: 1.0000\nF1-Score: 1.0000\nAUC-ROC: 1.0000\nRandom Forest CV Metrics:\nAccuracy: 0.9302\nPrecision: 0.9297\nRecall: 1.0000\nF1-Score: 0.9636\nAUC-ROC: 1.0000\nXGBoost CV Metrics:\nAccuracy: 0.9962\nPrecision: 0.9959\nRecall: 1.0000\nF1-Score: 0.9979\nAUC-ROC: 0.9750\nSVM CV Metrics:\nAccuracy: 0.9495\nPrecision: 0.9484\nRecall: 1.0000\nF1-Score: 0.9734\nAUC-ROC: 1.0000\n\nClassifier Performance Metrics (5-Fold CV with PCA):\n| Classifier          |   Accuracy |   Precision |   Recall |   F1-Score |   AUC-ROC |\n|:--------------------|-----------:|------------:|---------:|-----------:|----------:|\n| Logistic Regression |     1      |      1      |        1 |     1      |     1     |\n| Random Forest       |     0.9302 |      0.9297 |        1 |     0.9636 |     1     |\n| XGBoost             |     0.9962 |      0.9959 |        1 |     0.9979 |     0.975 |\n| SVM                 |     0.9495 |      0.9484 |        1 |     0.9734 |     1     |\n            Classifier  Accuracy  Precision  Recall  F1-Score  AUC-ROC\n0  Logistic Regression  1.000000   1.000000     1.0  1.000000    1.000\n1        Random Forest  0.930166   0.929713     1.0  0.963552    1.000\n2              XGBoost  0.996154   0.995918     1.0  0.997938    0.975\n3                  SVM  0.949548   0.948389     1.0  0.973446    1.000\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# File mapping\ndatasets = {\n    \"MIG\": \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv\",\n    \"ANOVA\": \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv\",\n    \"LASSO\": \"/kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv\",\n    \"mRMR+SVM-RFE\": \"/kaggle/input/tittititit/combined_top421_common_genes_mrmrsvmrfe.csv\"\n}\n\n# PCA variance thresholds to test\npca_thresholds = [0.99]\n\n# Results storage\nresults = {\n    \"Dataset\": [],\n    \"PCA_Variance\": [],\n    \"Classifier\": [],\n    \"Accuracy\": [],\n    \"Precision\": [],\n    \"Recall\": [],\n    \"F1-Score\": [],\n    \"AUC-ROC\": []\n}\n\n# Loop through datasets\nfor method, file_path in datasets.items():\n    df = pd.read_csv(file_path)\n    X = df.iloc[:, :-1].values\n    y = df.iloc[:, -1].values\n\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    \n    X_pca = pca.fit_transform(X_scaled)\n\n    classifiers = {\n            'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n            'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=100),\n            'XGBoost': XGBClassifier(scale_pos_weight=1, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n            'SVM': SVC(class_weight='balanced', random_state=42, probability=True)\n        }\n\n    for clf_name, clf in classifiers.items():\n            y_pred = cross_val_predict(clf, X_pca, y, cv=5)\n            y_proba = cross_val_predict(clf, X_pca, y, cv=5, method=\"predict_proba\")[:, 1]\n\n            results[\"Dataset\"].append(method)\n            results[\"Classifier\"].append(clf_name)\n            results[\"Accuracy\"].append(accuracy_score(y, y_pred))\n            results[\"Precision\"].append(precision_score(y, y_pred, zero_division=0))\n            results[\"Recall\"].append(recall_score(y, y_pred))\n            results[\"F1-Score\"].append(f1_score(y, y_pred))\n            results[\"AUC-ROC\"].append(roc_auc_score(y, y_proba))\n\n# Convert to DataFrame\nresults_df = pd.DataFrame(results)\nprint(results_df)\n\n# Save\nresults_df.to_csv(\"all_Results.csv\", index=False)\nprint(\"\\nResults saved to all_Results.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T15:32:07.865498Z","iopub.execute_input":"2025-08-15T15:32:07.865806Z","iopub.status.idle":"2025-08-15T15:32:26.853930Z","shell.execute_reply.started":"2025-08-15T15:32:07.865783Z","shell.execute_reply":"2025-08-15T15:32:26.853088Z"}},"outputs":[{"name":"stdout","text":"         Dataset  PCA_Variance           Classifier  Accuracy  Precision  \\\n0            MIG          0.99  Logistic Regression  1.000000   1.000000   \n1            MIG          0.99        Random Forest  0.926357   0.926070   \n2            MIG          0.99              XGBoost  0.988372   0.987552   \n3            MIG          0.99                  SVM  1.000000   1.000000   \n4          ANOVA          0.99  Logistic Regression  1.000000   1.000000   \n5          ANOVA          0.99        Random Forest  0.922481   0.922481   \n6          ANOVA          0.99              XGBoost  0.996124   0.995816   \n7          ANOVA          0.99                  SVM  1.000000   1.000000   \n8          LASSO          0.99  Logistic Regression  1.000000   1.000000   \n9          LASSO          0.99        Random Forest  0.922481   0.922481   \n10         LASSO          0.99              XGBoost  0.992248   0.991667   \n11         LASSO          0.99                  SVM  1.000000   1.000000   \n12  mRMR+SVM-RFE          0.99  Logistic Regression  1.000000   1.000000   \n13  mRMR+SVM-RFE          0.99        Random Forest  0.922481   0.922481   \n14  mRMR+SVM-RFE          0.99              XGBoost  0.988372   0.987552   \n15  mRMR+SVM-RFE          0.99                  SVM  1.000000   1.000000   \n\n    Recall  F1-Score   AUC-ROC  \n0      1.0  1.000000  1.000000  \n1      1.0  0.961616  0.997584  \n2      1.0  0.993737  1.000000  \n3      1.0  1.000000  1.000000  \n4      1.0  1.000000  1.000000  \n5      1.0  0.959677  1.000000  \n6      1.0  0.997904  1.000000  \n7      1.0  1.000000  1.000000  \n8      1.0  1.000000  1.000000  \n9      1.0  0.959677  0.998424  \n10     1.0  0.995816  1.000000  \n11     1.0  1.000000  1.000000  \n12     1.0  1.000000  1.000000  \n13     1.0  0.959677  0.999055  \n14     1.0  0.993737  1.000000  \n15     1.0  1.000000  1.000000  \n\nResults saved to all_Results.csv\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# new codes","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv')\n\n# Separate features and labels\nX = data.iloc[:, :-1]  # All columns except the last one (features)\ny = data.iloc[:, -1]   # Last column (class: 0 or 1)\n\n# Standardize features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Apply PCA with 95% variance retention\npca = PCA(n_components=0.95)\nX_pca = pca.fit_transform(X_scaled)\nprint(f\"Number of components selected: {pca.n_components_}\")\nprint(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_):.4f}\")\n\n# Class imbalance ratio\nclass_ratio = (y == 0).sum() / (y == 1).sum()\n\n# Initialize classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=100),\n    'XGBoost': XGBClassifier(scale_pos_weight=class_ratio, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n    'SVM': SVC(class_weight='balanced', random_state=42, probability=True)\n}\n\n# Results storage\nresults = {\n    'Classifier': [],\n    'Accuracy': [],\n    'Precision': [],\n    'Recall': [],\n    'F1-Score': [],\n    'AUC-ROC': []\n}\n\n# 5-fold Stratified Cross Validation\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor name, clf in classifiers.items():\n    acc_scores, prec_scores, rec_scores, f1_scores, auc_scores = [], [], [], [], []\n    \n    for train_idx, test_idx in skf.split(X_pca, y):\n        X_train, X_test = X_pca[train_idx], X_pca[test_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n        \n        clf.fit(X_train, y_train)\n        \n        y_pred = clf.predict(X_test)\n        y_proba = clf.predict_proba(X_test)[:, 1] if hasattr(clf, 'predict_proba') else clf.decision_function(X_test)\n        \n        acc_scores.append(accuracy_score(y_test, y_pred))\n        prec_scores.append(precision_score(y_test, y_pred, zero_division=0))\n        rec_scores.append(recall_score(y_test, y_pred))\n        f1_scores.append(f1_score(y_test, y_pred))\n        auc_scores.append(roc_auc_score(y_test, y_proba))\n    \n    results['Classifier'].append(name)\n    results['Accuracy'].append(np.mean(acc_scores))\n    results['Precision'].append(np.mean(prec_scores))\n    results['Recall'].append(np.mean(rec_scores))\n    results['F1-Score'].append(np.mean(f1_scores))\n    results['AUC-ROC'].append(np.mean(auc_scores))\n\n# Save results to DataFrame and CSV\nresults_df = pd.DataFrame(results).round(4)\nresults_df.to_csv('/kaggle/working/classifier_metrics_mig_pca_cv.csv', index=False)\n\n# Print\nprint(\"\\nClassifier Performance Metrics (5-Fold CV with PCA):\")\nprint(results_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T15:44:18.831574Z","iopub.execute_input":"2025-08-15T15:44:18.831956Z","iopub.status.idle":"2025-08-15T15:44:23.502262Z","shell.execute_reply.started":"2025-08-15T15:44:18.831928Z","shell.execute_reply":"2025-08-15T15:44:23.500241Z"}},"outputs":[{"name":"stdout","text":"Number of components selected: 98\nExplained variance ratio: 0.9508\n\nClassifier Performance Metrics (5-Fold CV with PCA):\n            Classifier  Accuracy  Precision  Recall  F1-Score  AUC-ROC\n0  Logistic Regression    1.0000     1.0000     1.0    1.0000    1.000\n1        Random Forest    0.9728     0.9722     1.0    0.9857    1.000\n2              XGBoost    0.9962     0.9959     1.0    0.9979    0.975\n3                  SVM    1.0000     1.0000     1.0    1.0000    1.000\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv')\n\n# Separate features and labels\nX = data.iloc[:, :-1]  # All columns except the last one (features)\ny = data.iloc[:, -1]   # Last column (class: 0 or 1)\n\n# Standardize features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Apply PCA with 95% variance retention\npca = PCA(n_components=0.95)\nX_pca = pca.fit_transform(X_scaled)\nprint(f\"Number of components selected: {pca.n_components_}\")\nprint(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_):.4f}\")\n\n# Class imbalance ratio\nclass_ratio = (y == 0).sum() / (y == 1).sum()\n\n# Initialize classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=100),\n    'XGBoost': XGBClassifier(scale_pos_weight=class_ratio, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n    'SVM': SVC(class_weight='balanced', random_state=42, probability=True)\n}\n\n# Results storage\nresults = {\n    'Classifier': [],\n    'Accuracy': [],\n    'Precision': [],\n    'Recall': [],\n    'F1-Score': [],\n    'AUC-ROC': []\n}\n\n# 5-fold Stratified Cross Validation\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor name, clf in classifiers.items():\n    acc_scores, prec_scores, rec_scores, f1_scores, auc_scores = [], [], [], [], []\n    \n    for train_idx, test_idx in skf.split(X_pca, y):\n        X_train, X_test = X_pca[train_idx], X_pca[test_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n        \n        clf.fit(X_train, y_train)\n        \n        y_pred = clf.predict(X_test)\n        y_proba = clf.predict_proba(X_test)[:, 1] if hasattr(clf, 'predict_proba') else clf.decision_function(X_test)\n        \n        acc_scores.append(accuracy_score(y_test, y_pred))\n        prec_scores.append(precision_score(y_test, y_pred, zero_division=0))\n        rec_scores.append(recall_score(y_test, y_pred))\n        f1_scores.append(f1_score(y_test, y_pred))\n        auc_scores.append(roc_auc_score(y_test, y_proba))\n    \n    results['Classifier'].append(name)\n    results['Accuracy'].append(np.mean(acc_scores))\n    results['Precision'].append(np.mean(prec_scores))\n    results['Recall'].append(np.mean(rec_scores))\n    results['F1-Score'].append(np.mean(f1_scores))\n    results['AUC-ROC'].append(np.mean(auc_scores))\n\n# Save results to DataFrame and CSV\nresults_df = pd.DataFrame(results).round(4)\nresults_df.to_csv('/kaggle/working/classifier_metrics_anova_pca_cv.csv', index=False)\n\n# Print\nprint(\"\\nClassifier Performance Metrics (5-Fold CV with PCA):\")\nprint(results_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T15:42:08.129984Z","iopub.execute_input":"2025-08-15T15:42:08.130369Z","iopub.status.idle":"2025-08-15T15:42:10.544959Z","shell.execute_reply.started":"2025-08-15T15:42:08.130316Z","shell.execute_reply":"2025-08-15T15:42:10.543958Z"}},"outputs":[{"name":"stdout","text":"Number of components selected: 177\nExplained variance ratio: 0.9902\n\nClassifier Performance Metrics (5-Fold CV with PCA):\n            Classifier  Accuracy  Precision  Recall  F1-Score  AUC-ROC\n0  Logistic Regression    1.0000     1.0000     1.0    1.0000    1.000\n1        Random Forest    0.9225     0.9225     1.0    0.9597    1.000\n2              XGBoost    0.9962     0.9959     1.0    0.9979    0.975\n3                  SVM    1.0000     1.0000     1.0    1.0000    1.000\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/ready-to-classifier/combined_top421_common_genes_lasso.csv')\n\n# Separate features and labels\nX = data.iloc[:, :-1]  # All columns except the last one (features)\ny = data.iloc[:, -1]   # Last column (class: 0 or 1)\n\n# Standardize features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Apply PCA with 95% variance retention\npca = PCA(n_components=0.99)\nX_pca = pca.fit_transform(X_scaled)\nprint(f\"Number of components selected: {pca.n_components_}\")\nprint(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_):.4f}\")\n\n# Class imbalance ratio\nclass_ratio = (y == 0).sum() / (y == 1).sum()\n\n# Initialize classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=100),\n    'XGBoost': XGBClassifier(scale_pos_weight=class_ratio, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n    'SVM': SVC(class_weight='balanced', random_state=42, probability=True)\n}\n\n# Results storage\nresults = {\n    'Classifier': [],\n    'Accuracy': [],\n    'Precision': [],\n    'Recall': [],\n    'F1-Score': [],\n    'AUC-ROC': []\n}\n\n# 5-fold Stratified Cross Validation\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor name, clf in classifiers.items():\n    acc_scores, prec_scores, rec_scores, f1_scores, auc_scores = [], [], [], [], []\n    \n    for train_idx, test_idx in skf.split(X_pca, y):\n        X_train, X_test = X_pca[train_idx], X_pca[test_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n        \n        clf.fit(X_train, y_train)\n        \n        y_pred = clf.predict(X_test)\n        y_proba = clf.predict_proba(X_test)[:, 1] if hasattr(clf, 'predict_proba') else clf.decision_function(X_test)\n        \n        acc_scores.append(accuracy_score(y_test, y_pred))\n        prec_scores.append(precision_score(y_test, y_pred, zero_division=0))\n        rec_scores.append(recall_score(y_test, y_pred))\n        f1_scores.append(f1_score(y_test, y_pred))\n        auc_scores.append(roc_auc_score(y_test, y_proba))\n    \n    results['Classifier'].append(name)\n    results['Accuracy'].append(np.mean(acc_scores))\n    results['Precision'].append(np.mean(prec_scores))\n    results['Recall'].append(np.mean(rec_scores))\n    results['F1-Score'].append(np.mean(f1_scores))\n    results['AUC-ROC'].append(np.mean(auc_scores))\n\n# Save results to DataFrame and CSV\nresults_df = pd.DataFrame(results).round(4)\nresults_df.to_csv('/kaggle/working/classifier_metrics_lasso_pca_cv.csv', index=False)\n\n# Print\nprint(\"\\nClassifier Performance Metrics (5-Fold CV with PCA):\")\nprint(results_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T15:42:14.752697Z","iopub.execute_input":"2025-08-15T15:42:14.753033Z","iopub.status.idle":"2025-08-15T15:42:16.977872Z","shell.execute_reply.started":"2025-08-15T15:42:14.752983Z","shell.execute_reply":"2025-08-15T15:42:16.976909Z"}},"outputs":[{"name":"stdout","text":"Number of components selected: 180\nExplained variance ratio: 0.9901\n\nClassifier Performance Metrics (5-Fold CV with PCA):\n            Classifier  Accuracy  Precision  Recall  F1-Score  AUC-ROC\n0  Logistic Regression    1.0000     1.0000     1.0    1.0000    1.000\n1        Random Forest    0.9225     0.9225     1.0    0.9597    1.000\n2              XGBoost    0.9962     0.9959     1.0    0.9979    0.975\n3                  SVM    1.0000     1.0000     1.0    1.0000    1.000\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/tittititit/combined_top421_common_genes_mrmrsvmrfe.csv')\n\n# Separate features and labels\nX = data.iloc[:, :-1]  # All columns except the last one (features)\ny = data.iloc[:, -1]   # Last column (class: 0 or 1)\n\n# Standardize features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Apply PCA with 95% variance retention\npca = PCA(n_components=0.95)\nX_pca = pca.fit_transform(X_scaled)\nprint(f\"Number of components selected: {pca.n_components_}\")\nprint(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_):.4f}\")\n\n# Class imbalance ratio\nclass_ratio = (y == 0).sum() / (y == 1).sum()\n\n# Initialize classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=100),\n    'XGBoost': XGBClassifier(scale_pos_weight=class_ratio, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n    'SVM': SVC(class_weight='balanced', random_state=42, probability=True)\n}\n\n# Results storage\nresults = {\n    'Classifier': [],\n    'Accuracy': [],\n    'Precision': [],\n    'Recall': [],\n    'F1-Score': [],\n    'AUC-ROC': []\n}\n\n# 5-fold Stratified Cross Validation\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor name, clf in classifiers.items():\n    acc_scores, prec_scores, rec_scores, f1_scores, auc_scores = [], [], [], [], []\n    \n    for train_idx, test_idx in skf.split(X_pca, y):\n        X_train, X_test = X_pca[train_idx], X_pca[test_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n        \n        clf.fit(X_train, y_train)\n        \n        y_pred = clf.predict(X_test)\n        y_proba = clf.predict_proba(X_test)[:, 1] if hasattr(clf, 'predict_proba') else clf.decision_function(X_test)\n        \n        acc_scores.append(accuracy_score(y_test, y_pred))\n        prec_scores.append(precision_score(y_test, y_pred, zero_division=0))\n        rec_scores.append(recall_score(y_test, y_pred))\n        f1_scores.append(f1_score(y_test, y_pred))\n        auc_scores.append(roc_auc_score(y_test, y_proba))\n    \n    results['Classifier'].append(name)\n    results['Accuracy'].append(np.mean(acc_scores))\n    results['Precision'].append(np.mean(prec_scores))\n    results['Recall'].append(np.mean(rec_scores))\n    results['F1-Score'].append(np.mean(f1_scores))\n    results['AUC-ROC'].append(np.mean(auc_scores))\n\n# Save results to DataFrame and CSV\nresults_df = pd.DataFrame(results).round(4)\nresults_df.to_csv('/kaggle/working/classifier_metrics_mrmr+svmrfe_pca_cv.csv', index=False)\n\n# Print\nprint(\"\\nClassifier Performance Metrics (5-Fold CV with PCA):\")\nprint(results_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T15:42:25.603980Z","iopub.execute_input":"2025-08-15T15:42:25.604315Z","iopub.status.idle":"2025-08-15T15:42:28.011380Z","shell.execute_reply.started":"2025-08-15T15:42:25.604294Z","shell.execute_reply":"2025-08-15T15:42:28.010544Z"}},"outputs":[{"name":"stdout","text":"Number of components selected: 177\nExplained variance ratio: 0.9901\n\nClassifier Performance Metrics (5-Fold CV with PCA):\n            Classifier  Accuracy  Precision  Recall  F1-Score  AUC-ROC\n0  Logistic Regression    1.0000     1.0000     1.0    1.0000    1.000\n1        Random Forest    0.9302     0.9297     1.0    0.9636    1.000\n2              XGBoost    0.9962     0.9959     1.0    0.9979    0.975\n3                  SVM    1.0000     1.0000     1.0    1.0000    1.000\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"#with cross & pca=0.95\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/ready-to-classifier/combined_top421_common_genes_mig.csv')\n\n# Separate features and labels\nX = data.iloc[:, :-1]  # All columns except the last one (class)\ny = data.iloc[:, -1]   # Last column (class: 0 or 1)\n\n# Apply PCA with 95% variance retention\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\npca = PCA(n_components=258)\nX_pca = pca.fit_transform(X_scaled)\nprint(f\"Number of components selected: {pca.n_components_}\")\nprint(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_):.4f}\")\n\n# Initialize classifiers with class weighting\nclass_ratio = (y == 0).sum() / (y == 1).sum()  # Ratio of negative to positive class\nclassifiers = {\n    'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=100),\n    'XGBoost': XGBClassifier(scale_pos_weight=class_ratio, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n    'SVM': SVC(class_weight='balanced', random_state=42, probability=True)\n}\n\n# Initialize results storage\nresults = {\n    'Classifier': [],\n    'Accuracy': [],\n    'Precision': [],\n    'Recall': [],\n    'F1-Score': [],\n    'AUC-ROC': []\n}\n\n# Perform 5-fold stratified cross-validation\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor name, clf in classifiers.items():\n    # Lists to store metrics for each fold\n    acc_scores, prec_scores, rec_scores, f1_scores, auc_scores = [], [], [], [], []\n    \n    # Cross-validation loop\n    for train_idx, test_idx in skf.split(X_pca, y):  # Use X_pca here\n        # Split data\n        X_train, X_test = X_pca[train_idx], X_pca[test_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n        \n        # Scale features (already handled by PCA, but reapply if needed)\n        scaler = StandardScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_test_scaled = scaler.transform(X_test)\n        \n        # Train classifier\n        clf.fit(X_train_scaled, y_train)\n        \n        # Predict on test fold\n        y_pred = clf.predict(X_test_scaled)\n        y_proba = clf.predict_proba(X_test_scaled)[:, 1] if hasattr(clf, 'predict_proba') else clf.decision_function(X_test_scaled)\n        \n        # Compute metrics\n        acc_scores.append(accuracy_score(y_test, y_pred))\n        prec_scores.append(precision_score(y_test, y_pred, zero_division=0))\n        rec_scores.append(recall_score(y_test, y_pred))\n        f1_scores.append(f1_score(y_test, y_pred))\n        auc_scores.append(roc_auc_score(y_test, y_proba))\n    \n    # Store mean of metrics\n    results['Classifier'].append(name)\n    results['Accuracy'].append(np.mean(acc_scores))\n    results['Precision'].append(np.mean(prec_scores))\n    results['Recall'].append(np.mean(rec_scores))\n    results['F1-Score'].append(np.mean(f1_scores))\n    results['AUC-ROC'].append(np.mean(auc_scores))\n    \n    print(f\"{name} CV Metrics:\")\n    print(f\"Accuracy: {np.mean(acc_scores):.4f}\")\n    print(f\"Precision: {np.mean(prec_scores):.4f}\")\n    print(f\"Recall: {np.mean(rec_scores):.4f}\")\n    print(f\"F1-Score: {np.mean(f1_scores):.4f}\")\n    print(f\"AUC-ROC: {np.mean(auc_scores):.4f}\")\n\n# Create results table\nresults_df = pd.DataFrame(results)\nresults_df = results_df.round(4)  # Round to 4 decimal places for readability\n\n# Save results as a markdown table\nmarkdown_table = results_df.to_csv(index=False)\n\n# Print and save the table\nprint(\"\\nClassifier Performance Metrics (5-Fold CV with PCA):\")\nprint(markdown_table)\n\n# Save the table to a file\nwith open('/kaggle/working/classifier_metrics_mig_pca_cv.csv', 'w') as f:\n    f.write(\"# Classifier Performance Metrics (mig, 5-Fold CV with PCA)\\n\")\n    f.write(markdown_table)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:07:37.026127Z","iopub.execute_input":"2025-08-15T16:07:37.026523Z","iopub.status.idle":"2025-08-15T16:07:39.502661Z","shell.execute_reply.started":"2025-08-15T16:07:37.026492Z","shell.execute_reply":"2025-08-15T16:07:39.501879Z"}},"outputs":[{"name":"stdout","text":"Number of components selected: 258\nExplained variance ratio: 1.0000\nLogistic Regression CV Metrics:\nAccuracy: 0.9225\nPrecision: 0.9225\nRecall: 1.0000\nF1-Score: 0.9597\nAUC-ROC: 0.3735\nRandom Forest CV Metrics:\nAccuracy: 0.9225\nPrecision: 0.9225\nRecall: 1.0000\nF1-Score: 0.9597\nAUC-ROC: 1.0000\nXGBoost CV Metrics:\nAccuracy: 0.9962\nPrecision: 0.9959\nRecall: 1.0000\nF1-Score: 0.9979\nAUC-ROC: 0.9750\nSVM CV Metrics:\nAccuracy: 0.9225\nPrecision: 0.9225\nRecall: 1.0000\nF1-Score: 0.9597\nAUC-ROC: 0.9778\n\nClassifier Performance Metrics (5-Fold CV with PCA):\nClassifier,Accuracy,Precision,Recall,F1-Score,AUC-ROC\nLogistic Regression,0.9225,0.9225,1.0,0.9597,0.3735\nRandom Forest,0.9225,0.9225,1.0,0.9597,1.0\nXGBoost,0.9962,0.9959,1.0,0.9979,0.975\nSVM,0.9225,0.9225,1.0,0.9597,0.9778\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n)\n\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\n# Step 1: Load combined dataset\ndf = pd.read_csv(\"/kaggle/input/ready-to-classifier/combined_top421_common_genes_anova.csv\")\n\n# Step 2: Separate features and target\nX = df.drop(columns=[\"Class\"])\ny = df[\"Class\"]  # Already encoded as 0 or 1 ‚Üí no need for LabelEncoder\n\n# Step 3: Define models with overfitting control\nmodels = {\n    \"SVM\": SVC(kernel=\"sigmoid\", C=0.003, probability=True, random_state=42),\n    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42),\n    \"XGBoost\": XGBClassifier(eval_metric='logloss',\n                         max_depth=3, subsample=0.7, reg_alpha=1, random_state=42),\n    \"Logistic Regression\": LogisticRegression(C=0.0045, max_iter=1000, random_state=42)\n}\n\n# Step 4: 5-fold stratified cross-validation evaluation\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor name, model in models.items():\n    print(f\"\\nüîç {name} Performance (5-fold CV):\")\n    \n    pipe = make_pipeline(StandardScaler(), model)\n    y_pred = cross_val_predict(pipe, X, y, cv=skf, method='predict')\n    y_prob = cross_val_predict(pipe, X, y, cv=skf, method='predict_proba')[:, 1]\n\n    print(f\"Accuracy:  {accuracy_score(y, y_pred):.4f}\")\n    print(f\"Precision: {precision_score(y, y_pred, zero_division=0):.4f}\")\n    print(f\"Recall:    {recall_score(y, y_pred):.4f}\")\n    print(f\"F1 Score:  {f1_score(y, y_pred):.4f}\")\n    print(f\"AUC-ROC:   {roc_auc_score(y, y_prob):.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}